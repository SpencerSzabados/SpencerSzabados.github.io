@Book{Apostol:1973,
	author = {Tom M. Apostol},
	title = {Mathematical Analysis: A Modern Approach to Advanced Calculus},
	publisher = {Pearson},
	year = {1973},
	edition = {2}
}

@Book{Arnold:1992,
	author = {Vladimir I. Arnol'd},
	editor = {Roger Cooke},
	title = {Ordinary Differential Equations},
	publisher = {Springer},
	year = {1992},
	edition = {English}
}

@Book{Bishop:2006,
	author = {Christopher M. Bishop},
	editor = {Michael Jordan and Jon Kleinberg and Berhard Sch\"{o}lkopf},
	title = {Pattern Recognition and Machine Learning},
	publisher = {Springer},
	year = {2006},
	series = {Information Science and Statistics},
	address = {New York, New York},
	edition = {1}
}

@Book{Bondy:2008,
	author = {J.A. Bondy and U.S.R Murty},
	editor = {S. Axler and K.A. Ribet},
	title = {Graph Theory},
	publisher = {Springer},
	year = {2008},
	series = {Graduate Texts in Mathematics},
}

@Book{Burago:2001,
	author = {Dmitri Burago and Yuri Burago and Sergei Ivanov},
	title = {A Course in Metric Geometry},
	series = {Graduate Studies in Mathematics},
	volume = {33},
	year = {2001},
	publisher = {American Mathematical Society}
}

@Book{DoCarmo:2016,
	author = {Manfredo P.do Carmo},
	title = {Differential Geometry of Curves and Surfaces},
	year = {2016},
	edition = {2},
	publisher = {Dover Publications, INC.},
	address = {Mineola, New York}
}

@Book{Casella:2001,
	author = {George Casella and Roger L. Berger},
	editor = {Carolyn Crockett and Tom Novack and Ann Day and Carol Reitz and Sue 	Ewing},
	title = {Statistical Inference},
	publisher = {Duxbury Thomson Learning},
	year = {2001},
	edition = {2},
	series = {Duxbury Adanced Series}
}

@Book{Cormen:2009,
	author = {Thomas H. Cormen and Charles E. Leiserson and Ronald L. Rivest and Clifford Stein},
	title = {Introduction to Algorithms},
	year = {2009},
	edition = {3},
	publisher = {The MIT Press},
	address = {Cambridge, Massachusetts}
}

@Book{Devroye:1985,
	author = {Luc Devroye and L\'aszl\'o Gy\"orfi},
	editor = {Vic Barnett and Ralph A. Bradley and J. Stuart Hunter and David G. Kendall and Rupert G. Miller, Jr. and Stephen M. Stigler and Geoffrey S. Watson},
	title = {Nonparametric Density Estimation The $L_1$ View},
	series = {Probability and Mathematical Statisticcs},
	publisher = {John Wiley \& Sons},
	year = {1985}
}

@Book{Diestel:2010,
	author = {Reinhard Diestel},
	editor = {S. Axler and K.A. Ribet},
	title = {Graph Theory},
	year = {2010},
	edition = {4},
	series = {Graduate Texts in Mathematics},
	publisher = {Springer},
	address = {Heidelberg Dordrecht London New York}
}

@Book{Drozdek:2005,
	author = {Adam Drozdek},
	title = {Data Structures and Algorithms in Java},
	year = {2005},
	edition = {2},
	publisher = {Course Technology},
	address = {25 Thomson Place, Boston, Massachusetts}
}

@Book{Gaughan:1993,
	author = {Edward D. Gaughan},
	editor = {Robert J. Wisner},
	title = {Introduction to Analysis},
	abstract = {Introduction to real analysis},
	keywords = {real analysis},
	publisher = {Brooks/Cole Publishing Company},
	address = {Pacific Grove, California},
	year = {1993},
	edition = {4}
}

@book{Gelman:2014,
	author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donlad B.},
	title = {Bayesian Data Analysis},
	year = {2014},
	edition = {3},
	publisher = {CRC Press},
	address = {6000 Broekn Sound Parkway NW}
}

@book{Goodfellow:2017,
	author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
	title={Deep Learning},
	publisher={MIT Press},
	year={2016},
	url = {http://www.deeplearningbook.org}
}

@Book{Hardt:2022,
  author = {Moritz Hardt and Benjamin Recht},
  title = {Patterns, predictions, and actions: Foundations of machine learning},
  year = {2022},
  publisher = {Princeton University Press}
}

@Book{Huber:2009,
	author = {Peter J. Huber and Elvezio M. Ronchetti},
	title = {Robust Statistics},
	year = {2009},
	edition = {2},
	publisher = {John Wiley \& Sons, Inc},
	address = {Hoboken, New Jersey}
}

@Book{Kearns:1994,
	author = {Michael J. Kearns and Umesh V. Vazirani},
	title = {An Introduction to Computational Learning Theory},
	year = {1994},
	publisher = {The MIT Press},
	address = {Cambridge, Massachusetts}
}

@book{Khalil:2014,
	author = {Khalil, Hassan K},
    title = {Nonlinear systems},
    year = {2014},
    edition = {3},
    publisher = {Pearson Education Limited},
    address = {Edinburgh Gate, Harlow}   
}

@Book{Lang:1986,
	author = {Serge Lang},
	title = {Introduction to Linear Algebra},
	year = {1986},
	edition = {2},
	series = {Undergraduate Texts in Mathematics},
	publisher = {Springer},
	address = {New York}
}

@Book{Marsden:1999,
	author = {Jerrold E. Marsden and Michael J. Hoffman},
	title = {Basic Complex Analysis},
	year = {1999},
	edition = {3},
	publisher = {W.H. Freeman and Company},
	address = {New York, New York}
}

@Book{McLachlan:2000,
	author = {McLachlan, Geoffrey J. and Peel, David},
	title = {Finite mixture models},
	year = {2000},
	series = {Wiley Series in Probabiliy and Statistics},
	publisher = {Wiley},
	address = {New York}
}

@Book{Miller:1982,
	author = {R.K. Miller and A.N. Michel},
	title = {Ordinary Differential Equations},
	year = {1982},
	publisher = {Academic Press},
	address = {New York, London}
}

@Book{Murphy:2012,
	author = {Kevin P. Murphy},
	title = {Machine Learning: A Probabilistic Perspective},
	year = {2012},
	publisher = {The MIT Press},
	address = {Cambridge, Massachusetts}
}

@Book{Modenov:1965,
	author = {P. S. Modenov and A. S. Parkhomenko},
	editor = {Michael B. P. Slater},
	title = {Geometric Transformations: Euclidean and Affine Transformations},
	year = {1965},
	volume = {1},
	edition = {English},
	address = {USA},
	location = {New York},
	publisher = {Academic Press}
}

@Book{Molloy:2002,
	author = {Michael Molloy and Bruce Reed},
	editor = {R.L. Graham and B.Korte and L.Lov{\'a}sz and A.Wigderson and G.M. Ziegler},
	title = {Graph Colouring and the Probabilistic Method},
	series = {Algorithms and Combinatorics},
	year = {2002},
	volume = {23},
	publisher = {Springer}
}

@Book{Munkres:2014,
	author = {Munkres, James},
	title = {Topology},
	publisher = {Springer, Pearson},
	series = {Graduate Texts in Mathematics},
	year = {2014},
	edition = {2}
}

@Book{Munkres:1991,
	author = {Munkre, James},
	title  = {Analysis on Manifolds},
	year = {1991},
	publisher = {Addison-Wesley Publishing Company}
}

@Book{Natagrajan:1991,
	author = {Balas K. Natarajan},
	editor = {Bob Klinginsmith},
	title = {Machine Learning: A Theoretical Approach},
	publisher = {Morgan Kaufmann},
	year = {1991},
	address = {USA},
	edition = {1}
}

@Book{Neal:1996,
	author = {Neal, Radford M.},
	title = {Bayesian Learning for Neural Networks},
	series = {Lecture Notes in Statistics},
	year = {1996},
	publisher = {Springer},
	address = {New York, New York}
}

@InBook{Perlin:2001,
	author = {Ken Perlin},
	editor = {M. Olano},
	title = {Real-Time Shading SIGGRAPH Course Notes},
	chapter = {2},
	year = {2001}
}

@Book{Roman:2008,
	author = {Steven Roman},
	editor = {S. Axler and K.A. Ribet},
	title = {Advanced Linear Algebra},
	series = {Gradutate Texts in Mathematics},
	year = {2008},
	volume = {135},
	publisher = {Springer}
}

@Book{Rotman:1995,
	author = {Joseph J. Rotman},
	editor = {S. Axler, F.W. Gehring, K.A. Ribet},
	title = {An Introduction to the Theory of Groups},
	publisher = {Springer},
	year = {1995},
	edition = {4}
}

@Book{Salamon:2002,
	author = {Salamon, Peter and Sibani, Paolo and Frost, Richard},
	title = {Facts, Conjectures, and Improvements for Simulated Annealing},
	year = {2002},
	publisher = {Society for Industrial and Applied Mathematics},
	doi = {10.1137/1.9780898718300}
}

@book{Samui:2020,
	author = {Pijush Samui and Dieu Tien Bui and Subrata Chakraborty and C. Ravinesh Deo},
	title = {Handbook of  Probabilistic Models},
	year = {2020},
	publisher = {Elsevier Inc},
	address = {San Diego, CA, USA},
	doi = {https://doi.org/10.1016/C2017-0-04723-7}
}

@Book{Spivak:1995,
	author = {Spivak, Michael},
	editor = {Gunning, Robert and Rossi, Hugo},
	title = {Calculus on manifolds},
	year = {1995},
	edition = {24},
	publisher = {Addison-Wesley Publishing Company}
}

@Book{Taylor:1998,
	author = {Howard M. Taylor and Samuel Karlin},
	title = {An Introduction to Stochastic Modeling},
	publisher = {Academic Press Limited},
	year = {1998},
	edition = {3}
}

@Book{Villani:2003,
	author = {Villani, CeÃÅdric},
	title = {Topics in optimal transportation},
	series = {Graduate studies in mathematics, v. 58},
	year = {2003},
	publisher = {American Mathematical Society},
	address = {Providence, R.I}
}

@Book{Yager:2008,
	editor = {Roland R. Yager and Liping Liu},	
	title = {Classic Works of the Dempster-Shafer Theory of Belief Fucntions},
	series = {Studies in Fuzziness and Soft Computing},
	year = {2008},
	publisher = {Springer},
	address = {Berlin, Hidelberg}
}

%
%
%===[ End of Book references ]=========================================
%
%

@Inproceedings{Afshani:2009,
	author = {Peyman Afshani and Timothy M. Chan},
	title = {Optimal Halfspace Range Reporting in Three Dimensions},
	booktitle = {Proceedings of the Twentieth Annual ACM-SIAM Symposium on Discrete Algorithms},
	series = {SODA '09},
	pages = {180--186},
	numpages = {7},
	year = {2009},
	publisher = {Society for Industrial and Applied Mathematics},
	address = {USA},
	location = {New York, New York}
}

@Misc{Agarwal:2019,
	author = {Pankaj K. Agarwal and Ravid Cohen and Dan Halperin and Wolfgang Mulzer},
	title = {Dynamic Maintenance of the Lower Envelope of Pseudo-Lines},
	year = {2019},
	publisher = {arXiv},
	doi = {10.48550/ARXIV.1902.09565}
}

@Article{Agarwal:1997,
	author = {Pankaj K. Agarwal and Jeff Erickson},
	title = {Geometric Range Searching and its Relatives},
	year = {1997},
	month = {September}
}

@Article{Agarwal:1996,
	author = {P.K. Agarwal and M. van Kreveld},
	title = {Connected Component and Simple Polygon Intersection Searching},
	journal = {Algorithmica},	
	year = {1996},
	volume = {15},
	pages = {626--660}
}

@Article{Agarwal:1993:1,
	author = {Pankaj K. Agarwal and Micha Sharir},
	title = {Applications of a new Space-Partitioning Technique},
	journal = {Discrete \& Computational Geometry},
	year = {1993},
	volume = {9},
	pages = {11--38}
}

@inproceedings{Agarwal:1993:2,
    author = { Pankaj K. Agarwal and Micha Sharir},
    title = {Ray Shooting amidst Convex Polytopes in Three Dimensions},
    booktitle = {Proceedings of the Fourth Annual ACM-SIAM Symposium on Discrete Algorithms},
    series = {SODA '93},
    year = {1993},
    pages = {260--270},
    numpages = {11},
    publisher = {Society for Industrial and Applied Mathematics},
    address = {USA},
    location = {Austin, Texas, USA},
    isbn = {0898713137}
}

@InProceedings{Akbari:2010,
	author = {Hoda Akbari and Mohammad Ghodsi},
	title = {Visibility maintenance of a moving segment observer inside polygons with holes},
	booktitle = {In Proceedings of the 22nd Canadian Conference on Computational Geometry (CCCG2010)},
	year = {2010},
	pages = {117--120}
}

@Article{Alt:1995,
	author = {H. Alt and M. Godau},
	title = {Computing The Frechet Distance Between Two Polygonal Curves},
	abstract = {As a measure for the resemblance of curves in arbitrary dimensions we consider the so-called Fr√©chet-distance, which is compatible with parametrizations of the curves. For polygonal chains P and Q consisting of p and q edges an algorithm of runtime O(pq log(pq)) measuring the Fr√©chet-distance between P and Q is developed. Then some important variants are considered, namely the Fr√©chet-distance for closed curves, the nonmonotone Fr√©chet-distance and a distance function derived from the Fr√©chet-distance measuring whether P resembles some part of the curve Q.},
	journal = {International journal of computational geometry & 	applications},
	year = {1995},
	volume = {5},
	number = {1n02},
	pages = {75--91}
}

@Inproceedings{Angluin:1992,
	author = {Dana Angluin},
	title = {Computational Learning Theory: Survey and Selected Bibliography},
	booktitle = {Proceedings of the Twenty-Fourth Annual ACM Symposium on Theory of Computing},
	year = {1992},
	pages = {351--369},
	numpages = {19},
	publisher = {Association for Computing Machinery},
	address = {USA},
    location = {New York},
	isbn = {0897915119},
	url = {https://doi.org/10.1145/129712.129746}
}

@incollection{Anthony:1993,
	author = {Martin Anthony and Norman Biggs},
	title = {Computational Learning Theory for Artificial Neural Networks},
	abstract = {This chapter presents the computational learning theory for artificial neural networks. There are many types of activity, which are commonly known as learning. The chapter discusses a mathematical model of one such process, known as the 'probably approximately correct‚Äô (or PAC) model. It illustrates how key problems of learning in artificial neural networks can be studied within this framework, presenting theoretical analyses of two important issues: the size of training sample that should be used, and the running time of learning algorithms: sample complexity and computational complexity. There are two sets of concepts inherent in the framework for learning. First, there is the set of concepts derived from the real world that it is proposed to recognize. When a set of concepts is determined in this way, the term concept space is used for it. Secondly, there is the set of concepts that the machine M is capable of recognizing. The set of all concepts which M determines is referred to as its hypothesis space.},
	editor = {J.G. Taylor},
	series = {North-Holland Mathematical Library},
	volume = {51},
	year = {1993},
	pages = {25--62},
	publisher = {Elsevier},
	issn = {0924-6509},
	doi = {https://doi.org/10.1016/S0924-6509(08)70034-5},
	url = {https://www.sciencedirect.com/science/article/pii/S0924650908700345}
}

@Article{Aronov:2002,
	author = {B. Aronov and L. J. Guibas and M. Teichmann and L. Zhang},
	title = {Visibility Queries and Maintenance in Simple Polygons},
	journal = {Discrete \& Computational Geometry},	
	year = {2002},
	volume = {27},
	pages = {461--483},
	publisher = {Springer-Verlag},
	address = {New York, New York}
}

@Article{Avis:1981,
  author = {David Avis and Godfried T. Toussaint},
  journal = {IEEE Transactions on Computers}, 
  title = {An Optimal Algorithm for Determining the Visibility of a Polygon from an Edge}, 
  year = {1981},
  volume = {C-30},
  number = {12},
  pages = {910--914},
  doi = {10.1109/TC.1981.1675729}
}

@inproceedings{Balaban:1995,
	author = {Ivan J. Balaban},
	title = {An Optimal Algorithm for Finding Segments Intersections},
	booktitle = {Proceedings of the Eleventh Annual Symposium on Computational Geometry},
	series = {SCG '95},
	year = {1995},
	pages = {211--219},
	numpages = {9},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	isbn = {0897917243},
	doi = {10.1145/220279.220302},
	url = {https://doi.org/10.1145/220279.220302}
}

@Article{Barron:1993,
	author = {A.R. Barron},
  	title = {Universal approximation bounds for superpositions of a sigmoidal function}, 
	journal = {IEEE Transactions on Information Theory}, 
  	year = {1993},	
  	volume = {39},
	number = {3},
	pages = {930--945}
}

@Article{Bartlett:2006,
	author = {Peter L. Bartlett and Michael I. Jordan and Jon D. Mcauliffe},
	title = {Convexity, Classification, and Risk Bounds},
 	abstract = {Many of the classification algorithms developed in the machine learning literature, including the support vector machine and boosting, can be viewed as minimum contrast methods that minimize a convex surrogate of the 0-1 loss function. The convexity makes these algorithms computationally efficient. The use of a surrogate, however, has statistical consequences that must be balanced against the computational virtues of convexity. To study these issues, we provide a general quantitative relationship between the risk as assessed using the 0-1 loss and the risk as assessed using any nonnegative surrogate loss function. We show that this relationship gives nontrivial upper bounds on excess risk under the weakest possible condition on the loss function-that it satisfies a pointwise form of Fisher consistency for classification. The relationship is based on a simple variational transformation of the loss function that is easy to compute in many applications. We also present a refined version of this result in the case of low noise, and show that in this case, strictly convex loss functions lead to faster rates of convergence of the risk than would be implied by standard uniform convergence arguments. Finally, we present applications of our results to the estimation of convergence rates in function classes that are scaled convex hulls of a finite-dimensional base class, with a variety of commonly used loss functions.},
	journal = {Journal of the American Statistical Association},
	year = {2006},
	volume = {101},
 	number = {473},
 	pages = {138--156},
 	publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 	url = {http://www.jstor.org/stable/30047445}
}

@Article{Bates:2021,
	author = {Bates, Stephen and Angelopoulos, Anastasios and Lei, Lihua and Malik, Jitendra and Jordan, Michael},
	title = {Distribution-Free, Risk-Controlling Prediction Sets},
	journal = {Jouranl of the ACM},
	year = {2021},
	volume = {68},
	number = {6},
	numpages = {34},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	doi = {10.1145/3478535}
}

@Misc{Bayer:1973,
	author = {B.E. Bayer},
	title = {An Optimum Method For Two-Level Rendition of Continuous-Tone Pictures},
	year = {1973},
	publisher = {Research Labatories, Eastman Kadak Company},
	address = {Rochester, New York}
}

@Article{Bengio:1994,
	author = {Y. Bengio and P. Simard and P. Frasconi},
	title = {Learning Long-term Dependencies with Gradient Descent is Difficult},
	abstract = {Recurrent neural networks can be used to map input sequences to output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent neural networks to
perform tasks in which the temporal contingencies present in the input/output sequences span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases...},
	journal = {IEEE Transactions on Neural Networks},
	year = {1994},
	volume = {5},
	number = {2},
	pages = {157--166}
}

@Article{Bi:2012,
	author = {Yaxin Bi},
	title = {The impact of diversity on the accuracy of evidential classifier ensembles},
	journal = {International Journal of Approximate Reasoning},
	year = {2012},
	volume = {53},
	number = {4},
	pages = {584-607},
	doi = {https://doi.org/10.1016/j.ijar.2011.12.011}
}

@InProceedings{Birrell:2022,
	author = {Birrell, Jeremiah and Katsoulakis, Markos and Rey-Bellet, Luc and Zhu, Wei},
	title = {Structure-preserving {GAN}s},
	booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
	editor = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
	series = {Proceedings of Machine Learning Research},
	year = {2022},
	volume = {162},
	pages = {1982--2020},
  	publisher = {PMLR},
  	url = {https://proceedings.mlr.press/v162/birrell22a.html}
}

@Article{Bloom:1970,
    author = {Bloom, Burton H.},
    title = {Space/Time Trade-Offs in Hash Coding with Allowable Errors},
	journal = {Communications of the ACM},    
    year = {1970},
    volume = {13},
    number = {7},
    pages = {422--426},
    numpages = {5},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    doi = {10.1145/362686.362692}
}

@Article{Bonato:2021,
	author = {Anothony Bonato},
	title = {A Survey of Graph Burning},
	journal = {Contributions to Discrete Mathematics},
	year = {2021},
	volume = {16},
	number = {1},
	pages = {185--197}
}

@InProceedings{Bozanis:1995,
	author = {Panayiotis Bozanis and Nectarios Kitsios and Christos Makris and Athanasios Tsakalidis},
	title = {New upper bounds for generalized intersection searching problems},
	abstract = {Generalized intersection searching problems is a class of problems that constitute an extension of their standard counterparts. In such problems, we are given a set of colored objects and we want to report or count the distinct colors of the objects intersected by a query object. Many solutions have appeared for both iso-oriented and non-iso-oriented objects. We show how to improve the bounds of several generalized intersection searching problems as well as how to obtain upper bounds for some problems not treated before.},
	booktitle = {Automata, Languages and Programming},
	year = {1995},
	pages = {464--474},
	publisher = {Springer},
	address = {Berlin, Heidelberg},
	isbn = {978-3-540-49425-6}
}

@Article{Breiman:2001,
	author = {Leo Breiman},
	title = {Statistical Modeling: The Two Cultures},
	abstract = {There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown. The statistical community has been committed to the almost exclusive use of data models. This commitment has led to irrelevant theory, questionable conclusions, and has kept
statisticians from working on a large range of interesting current problems. Algorithmic modeling, both in theoryand practice, has developed rapidlyin fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools.},
	journal = {Statistical Science},
	year = {2001},
	volume = {16},
	number = {3},
	pages = {199--231}
}

@Article{Breiman:1993,
  	author = {Leo Breiman},
	title = {Hinging hyperplanes for regression, classification, and function approximation}, 
   	journal = {IEEE Transactions on Information Theory}, 
   	year = {1993},
	volume = {39},
	number = {3},
  	pages = {999--1013},
  	doi = {10.1109/18.256506}
}

@Article{Brenier:1991,
	author = {Brenier, Yann},
	title = {Polar factorization and monotone rearrangement of vector-valued functions},
	journal = {Communications on Pure and Applied Mathematics},
	year = {1991},
	volume = {44},
	number = {4},
	pages = {375--417},
	doi = {https://doi.org/10.1002/cpa.3160440402}
}

@inproceedings{Brown:2020,
    author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
    title = {Language Models Are Few-Shot Learners},
    abstract = {We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.},
    booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
    series = {NIPS'20},
    year = {2020},
    volume = {34},
    pages = {1877--1901},
    publisher = {Curran Associates Inc.},
    address = {Red Hook, NY, USA},
    isbn = {9781713829546}
}

@Inproceedings{Buchin:2009,
    author = {Kevin Buchin and Maike Buchin and Yusu Wang},
    title = {Exact Algorithms for Partial Curve Matching via the Fr\'{e}chet Distance},
    abstract = {Curve matching is a fundamental problem that occurs in many applications. In this paper, we study the problem of measuring partial similarity between curves. Specifically, given two curves, we wish to maximize the total length of subcurves that are close to each other, where closeness is measured by the Fr\'{e}chet distance, a common distance measure for curves. The resulting maximal length is called the partial Fr\'{e}chet similarity between the two input curves.Given two polygonal curves P and Q in Rd of size m and n, respectively, we present the first exact algorithm that runs in polynomial time to compute fŒ¥(P, Q), the partial Fr\'{e}chet similarity between P and Q, under the L1 and L‚àû norms. Specifically, we formulate the problem of computing fŒ¥(P, Q) as a longest path problem, and solve it in O(mn(m + n) log(mn)) time, under the L1 or L‚àû norm, using a "shortest-path map" type decomposition. To the best of our knowledge, this is the first paper to study this natural definition of partial curve similarity in the continuous setting (with all points in the curve considered), and present a polynomial-time exact algorithm for it.},
	booktitle = {Proceedings of the Twentieth Annual ACM-SIAM Symposium on Discrete Algorithms},
    pages = {645--654},
    numpages = {10},
    series = {SODA '09},
    year = {2009},
    publisher = {Society for Industrial and Applied Mathematics},
    address = {USA},
    location = {New York}
}

@Article{Bzdok:2018,
	author = {D. Bzdok and N. Altman and M. Krzywinski},
	title = {Statistics versus machine learning},
	journal = {Nature Methods},
	year = {2018},
	volume = {15},
	number = {4},
	pages = {233--234}
}

@Article{Sanchez-Cauce:2022,
	author = {Raquel S√°nchez-Cauce and Iago Par√≠s and Francisco Javier D√≠ez},
	title = {Sum-Product Networks: A Survey}, 
  	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  	year = {2022},
  	volume = {44},
  	number = {7},
  	pages = {3821--3839},
  	doi = {10.1109/TPAMI.2021.3061898}
}

@Article{Casella:1992,
	author = {Casella, George and George, Edward I.},
	title = {Explaining the Gibbs Sampler},
	journal = {The American Statistician},
	year = {1992},
	volume = {46},
 	number = {3},
 	pages = {167--174},
 	publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 	url = {http://www.jstor.org/stable/2685208}
}

@Article{Chan:1996,
	author = {T.M. Chan},
	title = {Optimal Output-Sensitive Convex Hull Algorithms in Two and Three Dimensions},
	journal = {Discrete \& Computational Geometry},
	year = {1996},
	volume = {16},
	pages = {361--368},
	doi = {10.1007/BF02712873}
}

@Article{Chandler:1990,
	title = {A recursive technique for rendering parametric curves},
	author = {Chandler, Richard E.},
	journal = {Computers & Graphics},
	year = {1990},
	volume = {14},
	number = {3},
	pages = {477--479},
	doi = {https://doi.org/10.1016/0097-8493(90)90069-A}
}

@Article{Chatterji:2022,
	author = {Chatterji, Niladri S. and Bartlett, Peter L. and Long, Philip M.},
	title = {Oracle lower bounds for stochastic gradient sampling algorithms},
	journal = {Bernoulli},
	year = {2022},
	volume = {28},
	number = {2},
	pages = {1074 -- 1092},
	publisher = {Bernoulli Society for Mathematical Statistics and Probability},
	doi = {10.3150/21-BEJ1377}
}

@article{Chazelle:1992,
	author = {Bernard Chazelle and Herbert Edelsbrunner},
	title = {An Optimal Algorithm for Intersecting Line Segments in the Plane},
	abstract = {The main contribution of this work is an O(n log n + k)-time algorithm for computing all k intersections among n line segments in the plane. This time complexity is easily shown to be optimal. Within the same asymptotic cost, our algorithm can also construct the subdivision of the plane defined by the segments and compute which segment (if any) lies right above (or below) each intersection and each endpoint. The algorithm has been implemented and performs very well. The storage requirement is on the order of n + k in the worst case, but it is considerably lower in practice. To analyze the complexity of the algorithm, an amortization argument based on a new combinatorial theorem on line arrangements is used.},
	journal = {J. ACM},
	year = {1992},
	month = {jan},
	volume = {39},
	number = {1},
	pages = {1--54},
	numpages = {54},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	issn = {0004-5411},
	doi = {10.1145/147508.147511},
	url = {https://doi.org/10.1145/147508.147511},
}

@Article{Chazelle:1991,
	author = {Bernard Chazelle},
	title = {Triangulating a Simple Polygon in Linear Time},
	journal = {Discrete \& Computational Geometry},
	year = {1991},
	volume = {6},
	pages = {485--524}
}

@Article{Chazelle:1989,
	author = {Bernard Chazelle and Leonidas J. Guibas},
  	title = {Visibility and Intersection Problems in Plane Geometry},
  	journal = {Discrete \& Computational Geometry},
  	year = {1989},
  	volume = {4},
  	pages = {551--581}
}

@Article{Chazelle:1985,
    author = {Bernard Chazelle and Leo J. Guibas and D. T. Lee},
    title = {The Power of Geometric Duality},
    abstract = {This paper uses a new formulation of the notion of duality that allows the unified treatment of a number of geometric problems. In particular, we are able to apply our approach to solve two long-standing problems of computational geometry: one is to obtain a quadratic algorithm for computing the minimum-area triangle with vertices chosen amongn points in the plane; the other is to produce an optimal algorithm for the half-plane range query problem. This problem is to preprocessn points in the plane, so that given a test half-plane, one can efficiently determine all points lying in the half-plane. We describe an optimalO(k + logn) time algorithm for answering such queries, wherek is the number of points to be reported. The algorithm requiresO(n) space andO(n logn) preprocessing time. Both of these results represent significant improvements over the best methods previously known. In addition, we give a number of new combinatorial results related to the computation of line arrangements.},
    journal = {BIT},
    year = {1985},
    volume = {25},
    number = {1},
    pages = {76‚Äì-90},
    numpages = {15},
    publisher = {BIT Computer Science and Numerical Mathematics},
    address = {USA},
    issn = {0006-3835},
    doi = {10.1007/BF01934990},
    url = {https://doi.org/10.1007/BF01934990}
}

@Article{Chazelle:1983,
	author = {Bernard Chazelle},
	title = {The Polygon Containment Problem},
	journal = {Advances in Computing Research},
	year = {1983},
	volume = {1},
	pages = {1--33}
}

@InProceedings{Chen:2022,
	author = {Chen, Yuansi and Eldan, Ronen},
	title = {Localization Schemes: A Framework for Proving Mixing Bounds for Markov Chains (extended abstract)},
	booktitle = {2022 IEEE 63rd Annual Symposium on Foundations of Computer Science (FOCS)},
	year = {2022},
	pages = {110--122},
	publisher = {IEEE Computer Society},
	address = {Los Alamitos, CA, USA},
	doi = {10.1109/FOCS54457.2022.00018}
}

@InProceedings{Chen:2018,
	title = {A Closer Look at Few-shot Classification},
	author = {Wei-Yu Chen and Yen-Cheng Liu and Zsolt Kira and Yu-Chiang Frank Wang and Jia-Bin Huang},
	booktitle = {International Conference on Learning Representations},
	year = {2019},
	url = {https://openreview.net/forum?id=HkxLXnAcFQ}
}

@InProceedings{ChenRBD:2018,
	author = {Chen, Ricky T. Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
	title = {Neural Ordinary Differential Equations},
 	booktitle = {Advances in Neural Information Processing Systems},
 	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 	year = {2018},
 	volume = {31},
 	pages = {},
 	publisher = {Curran Associates, Inc.},
	url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/69386f6bb1dfed68692a24c8686939b9-Paper.pdf}
}

@Article{Chen:2015,
	author = {Danny Z. Chen and Haitao Wang},
	title = {Weak visibility queries of line segments in simple polygons},
	journal = {Computational Geometry},
	year = {2015},
	volume = {48},
	number = {6},
	pages = {443--452},
	issn = {0925-7721},
	url = {https://www.sciencedirect.com/science/article/pii/S0925772115000140}
}

@Inproceedings{Cheng:2014,
	title = {Language modeling with sum-product networks},
  	author = {Wei Cheng and Stanley Kok and Hoai Vu Pham and Hai Leong Chieu and Kian Ming Adam Chai},
  	booktitle={Proc. Interspeech 2014},
  	year = {2014},
  	pages = {2098--2102},
  	doi = {10.21437/Interspeech.2014-476}
}

@Article{Cheng:1992,
	author = {Siu Wing Cheng and Ravi Janardan},
	title = {Algorithms for ray-shooting and intersection searching},
	journal = {Journal of Algorithms},
	year = {1992},
	volume = {13},
	number = {4},
	pages = {670--692},
	url = {https://www.sciencedirect.com/science/article/pii/019667749290062H}
}

@Article{Chiang:1987,
	author = {Chiang, Tzuu-Shuh and Hwang, Chii-Ruey and Sheu, Shuenn Jyi},
	title = {Diffusion for Global Optimization in $\mathbb{R}^n$},
	journal = {SIAM Journal on Control and Optimization},
	volume = {25},
	number = {3},
	pages = {737--753},
	year = {1987},
	doi = {10.1137/0325042}
}

@InProceedings{Chilkuri:2021,
  	title = {Parallelizing Legendre Memory Unit Training},
  	author = {Chilkuri, Narsimha Reddy and Eliasmith, Chris},
  	booktitle = {Proceedings of the 38th International Conference on Machine Learning},
  	editor = {Meila, Marina and Zhang, Tong},
  	series = {Proceedings of Machine Learning Research},
  	year = {2021},
  	volume = {139},
  	pages = {1898--1907},
  	publisher = {PMLR},
  	url = {https://proceedings.mlr.press/v139/chilkuri21a.html}
}

@Article{Claeskens:2014,
	author = {Gerda Claeskens and Mia Hubert and Leen Slaets and Kaveh Vakili},
	title = {Multivariate Functional Halfspace Depth},
 	journal = {Journal of the American Statistical Association},
 	year = {2014},
 	volume = {109},
 	number = {505},
 	pages = {411--423},
 	publisher = {American Statistical Association, Taylor \& Francis, Ltd.},
 	url = {http://www.jstor.org/stable/24247164}
}

@Article{Clare:2021,
	author = {Clare, Mariana C.A. and Jamil, Omar and Morcrette, Cyril J.},
	title = {Combining distribution-based neural networks to predict weather forecast probabilities},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	year = {2021},
	volume = {147},
	number = {741},
	pages = {4337--4357},
	doi = {https://doi.org/10.1002/qj.4180}
}

@Article{Cuevas:2007,
	author = {Febrero A. Cuevas and R.M. Fraiman},
	title = {Robust estimation and classification for functional data via projection-based depth notions},
	journal = {Computational Statistics},
	year = {2007},
	volume = {22},
	pages = {481--496},
	doi = {10.1007/s00180-007-0053-0},
	url = {https://doi.org/10.1007/s00180-007-0053-0}
}

@Article{Cybenko:1989,
  	title = {Approximation by Superpositions of a Sigmoidal Function},
  	author = {George V. Cybenko},
  	journal = {Mathematics of Control, Signals and Systems},
  	year = {1989},
  	volume = {2},
  	pages = {303--314}
}

@Article{Dempster:2008,
	author = {A.P. Dempster},
	title = {The Dempster‚ÄìShafer calculus for 	statisticians},
	journal = {International Journal of Approximate Reasoning},
	year = {2008},
	volume = {48},
	number = {2},
	pages = {365--377},
	doi = {https://doi.org/10.1016/j.ijar.2007.03.004}
}

@Article{Denoeux:2010,
	author = {Thierry Den≈ìux and Zoulficar Younes and Fahed Abdallah},
	title = {Representing uncertainty on set-valued variables using belief functions},
	year = {2010},
	journal = {Artificial Intelligence},
	volume = {174},
	number = {7},
	pages = {479--499},
	doi = {https://doi.org/10.1016/j.artint.2010.02.002}
}

@Article{Denoeux:2000,
	author = {Den≈ìux, T.},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans}, 
  	title = {A neural network classifier based on Dempster-Shafer theory}, 
  	year = {2000},
 	volume = {30},
  	number = {2},
  	pages = {131--150},
	doi = {10.1109/3468.833094}
}

@Article{Durocher:2017,
	author = {Stephane Durocher and Alexandre Leblanc and Matthew Skala},
	title = {The Projection Median as a Weighted Average},
	abstract = {The projection median of a set of points in is a robust geometric generalization of the notion of univariate median to higher dimensions. In its original definition, the projection median is expressed as a normalized integral of the medians of the projections of onto all lines through the origin. We introduce a new definition in which the projection median is expressed as a weighted mean of , and show the equivalence of the two definitions. In addition to providing a definition whose form is more consistent with those of traditional statistical estimators of location, this new definition for the projection median allows many of its geometric properties to be established more easily, as well as enabling new randomized algorithms that compute approximations of the projection median with increased accuracy and efficiency, reducing computation time from to , where denotes the number of random projections sampled. Selecting or , suffices for our algorithms to return a point within relative distance of the true projection median with high probability, resulting in running times and respectively, for any fixed.},
	journal = {Journal of Computational Geometry},
	year = {2017},
	volume = {8},
	number = {1},
	pages = {78--104}
}

@InProceedings{Dwivedi:2018,
	author = {Dwivedi, Raaz and Chen, Yuansi and Wainwright, Martin J and Yu, Bin},
	title = {Log-concave sampling: Metropolis-Hastings algorithms are fast!},
	booktitle = {Proceedings of the 31st Conference On Learning Theory},
	series = {Proceedings of Machine Learning Research},
	editor = {Bubeck, S√©bastien and Perchet, Vianney and Rigollet, Philippe},
	year = {2018},
	volume = {75},
	pages = {793--797},
	publisher = {PMLR},
	url = {https://proceedings.mlr.press/v75/dwivedi18a.html}
}

@Article{Edelsbrunner:1989,
	author = {Herbert Edelsbrunner and Leonidas J. Guibas and Micha Sharir},
	title = {The Upper Envolope of Piecewise Linear Functions: Algorithms and Applications},
	abstract = {This paper studies applications of envelopes of piecewise linear functions to problems in computational geometry. Among these applications we find problems involving hidden line/surface elimination, motion planning, transversals of polytopes, and a new type of Voronoi diagram for clusters of points. All results are either combinatorial or computational in nature. They are based on the combinatorial analysis in two companion papers [PS] and [E2] and a divide-and-conquer algorithm for computing envelopes described in this paper.},
	journal = {Discrete \& Computational Geometry},
	year = {1989},
	volume = {4},	
	pages = {311--336}
}

@Article{Efrat:2007,
    author = {Fan A. Efrat and Q. Venkatasubramanian},
	title = { Curve Matching, Time Warping, and Light Fields: New Algorithms for Computing Similarity between Curves},
	journal = {J Math Imaging Vis},
	year = {2007},
	volume = {27},
	pages = {203--216},
	doi = {10.1007/s10851-006-0647-0},
	url = {https://doi.org/10.1007/s10851-006-0647-0}
}

@InProceedings{Engel:2018,
	author = {Engel, Jesse and Hoffman, Matthew and Roberts, Adam},
	title = {Latent Constraints: Learning to Generate Conditionally from Unconditional Generative Models},
	booktitle = {International Conference on Learning Representations},
	year = {2018},
	url = {https://openreview.net/forum?id=Sy8XvGb0-}
}

@Article{Estrada:2016,
	author = {Estrada, Ricardo and Rubin, Boris},
	title = {Null spaces of Radon transforms},
	abstract = {We obtain new descriptions of the null spaces of several projectively equivalent transforms in integral geometry. The paper deals with the hyperplane Radon transform, the totally geodesic transforms on the sphere and the hyperbolic space, the spherical slice transform, and the Cormack‚ÄìQuinto spherical mean transform for spheres through the origin. The consideration extends to the corresponding dual transforms and the relevant exterior/interior modifications. The method relies on new results for the Gegenbauer‚ÄìChebyshev fractional integrals.},
	journal = {Advances in Mathematics},
	year = {2016},
	volume = {290},
	pages = {1159--1182},
	publisher = {Elsevier Inc}
}

@InProceedings{Fang:2021,
	author = {Cong Fang and Hanze Dong and Tong Zhang},
	title = {Mathematical Models of Overparameterized Neural Networks},
	booktitle = {Proceedings of the IEEE},
	year = {2021},
	volume = {109},
	number = {5},
	pages = {683--703},
	publisher = {IEEE},
	doi = {10.1109/JPROC.2020.3048020}
}

@Article{Ferraty:2003,
	author = {F. Ferraty and P. Vieu},
	title = {Curves discrimination: a nonparametric functional approach},
	journal = {Computational Statistics & Data Analysis},
	year = {2003},
	volume = {44},
	number = {1-2},
	pages = {161-173}
}

@Article{Fraiman:2001,
	author = {Ricardo Fraiman and Graciela Muniz},
	title = {Trimmed means for functional data},
	journal = {Test},
	year = {2001},
	volume = {10},
	pages = {419--440},
	doi = {10.1007/BF02595706},
	url = {https://doi-org.uml.idm.oclc.org/10.1007/BF02595706}
}

@Article{Friedman:1984,
	author = {Jerome H. Friedman and Werner Stuetzle and Anne Schroeder},
	title = {Projection Pursuit Density Estimation},
 	abstract = {The projection pursuit methodology is applied to the multivariate density estimation problem. The resulting nonparametric procedure is often less biased than the kernel and near-neighbor methods. In addition, graphical information is produced that can be used to help gain geometric insight into the multivariate data distribution.},
 	journal = {Journal of the American Statistical Association},
 	year = {1984},
 	volume = {79},
 	number = {387},
 	pages = {599--608},
 	publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 	url = {http://www.jstor.org/stable/2288406}
}

@Article{Gelfand:1990,
	author = {Alan E. Gelfand and Adrian F. M. Smith},
	title = {Sampling-Based Approaches to Calculating Marginal Densities},
 	abstract = {Stochastic substitution, the Gibbs sampler, and the sampling-importance-resampling algorithm can be viewed as three alternative sampling- (or Monte Carlo-) based approaches to the calculation of numerical estimates of marginal probability distributions. The three approaches will be reviewed, compared, and contrasted in relation to various joint probability structures frequently encountered in applications. In particular, the relevance of the approaches to calculating Bayesian posterior densities for a variety of structured models will be discussed and illustrated.},
	journal = {Journal of the American Statistical Association},
	year = {1990},
	volume = {85},
 	number = {410},
 	pages = {398--409},
 	publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
	url = {http://www.jstor.org/stable/2289776}
}

@InProceedings{Gens:2013,
	author = {Robert Gens and Domingos Pedro},
	title = {Learning the Structure of Sum-Product Networks},
	abstract = {Sum-product networks (SPNs) are a new class of deep probabilistic models. SPNs can have unbounded treewidth but inference in them is always tractable. An SPN is either a univariate distribution, a product of SPNs over disjoint variables, or a weighted sum of SPNs over the same variables. We propose the first algorithm for learning the structure of SPNs that takes full advantage of their expressiveness. At each step, the algorithm attempts to divide the current variables into approximately independent subsets. If successful, it returns the product of recursive calls on the subsets; otherwise it returns the sum of recursive calls on subsets of similar instances from the current training set. A comprehensive empirical study shows that the learned SPNs are typically comparable to graphical models in likelihood but superior in inference speed and accuracy.},
  	booktitle = {Proceedings of the 30th International Conference on Machine Learning},
  	editor = {Sanjoy Dasgupta and David McAllester},
  	series = {Proceedings of Machine Learning Research},
  	volume = {28},
  	number = {3},
  	year = {2013},
  	pages = {873--880},
  	address = {Atlanta, Georgia, USA},
  	month = {17--19 Jun},
  	publisher = {PMLR}
}

@InProceedings{Gens:2012,
	author = {Robert Gens and Pedro Domingos},
	title = {Discriminative Learning of Sum-Product Networks},
 	booktitle = {Proceedings of the 25th International Conference on Neural Information Processing Systems},
 	editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 	series = {NIPS'12},
 	year = {2012},
 	volume = {2},
 	pages = {3239--3247},
 	publisher = {Curran Associates, Inc.},
 	url = {https://proceedings.neurips.cc/paper/2012/file/573f7f25b7b1eb79a4ec6ba896debefd-Paper.pdf}
}

@Article{Ghosh:1991,
	author = {Subir Kumar Ghosh and David M. Mount},
	title = {An Output-Sensitive Algorithm for Computing Visibility Graphs},
	journal = {SIAM Journal on Computing},
	year = {1991},
	volume = {20},
	number = {5},
	pages = {888--910}
}

@Article{Gijbels:2017,
	author = {Ir√®ne Gijbels and Stanislav Nagy},
	title = {On a General Definition of Depth for Functional Data},
	abstract = {In this paper, we provide an elaboration on the desirable properties of statistical depths for functional data. Although a formal definition has been put forward in the literature, there are still several unclarities to be tackled, and further insights to be gained. Herein, a few interesting connections between the wanted properties are found. In particular, it is demonstrated that the conditions needed for some desirable properties to hold are extremely demanding, and virtually impossible to be met for common depths. We establish adaptations of these properties which prove to be still sensible, and more easily met by common functional depths.},
	keywords = {data depth, functional data, multivariate statistics, robustness},
	journal = {Statistical Science},
	year = {2017},
	volume = {32},
	number = {4},
	pages = {630--639},
	publisher = {Institute of Mathematical Statistics},
	doi = {10.1214/17-STS625},
	url = {https://doi.org/10.1214/17-STS625}
}

@Unpublished{Gonzalez-Sanz:2022,
	author = {Gonz{\'a}lez-Sanz, Alberto and de Lara, Lucas and B{\'e}thune, Louis and Loubes, Jean-Michel},
 	title = {GAN Estimation of Lipschitz Optimal Transport Maps},
  	year = {2022},
  	url = {https://hal.science/hal-03575178},
  	note = {working paper or preprint}
}

@Article{Graham:1972,
	author = {R.L. Graham},
	title = {An efficient algorith for determining the convex hull of a finite planar set},
	journal = {Information Processing Letters},
	volume = {1},
	number = {4},
	pages = {132--133},
	year = {1972},
	issn = {0020-0190},
	doi = {https://doi.org/10.1016/0020-0190(72)90045-2},
	url = {https://www.sciencedirect.com/science/article/pii/0020019072900452}
}

@InProceedings{GuthCBM:2022,
	author = {Guth, Florentin and Coste, Simon and Bortoli, Valentin De and Mallat, St{\'e}phane},
	title = {Wavelet Score-Based Generative Modeling},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
	year = {2022},
	url = {https://openreview.net/forum?id=xZmjH3Pm2BK}
}

@Article{Guibas:1989,
	author = {Leonidas J. Guibas and John Hershberger},
	title = {Optimal shortest path queries in a simple polygon},
	abstract = {Let P be a simple polygon with n sides. This paper shows how to preprocess the polygon so that, given two query points p and q inside P, the length of the shortest path inside the polygon from p to q can be found in time O(log n). The path itself must be polygonal and can be extracted in additional time proportional to the number of turns it makes. The preprocessing consists of triangulation plus a linear amount of additional work.},
	journal = {Journal of Computer and System Sciences},
	year = {1989},
	volume = {39},
	number = {2},
	pages = {126--152},
	issn = {0022-0000},
	doi = {https://doi.org/10.1016/0022-0000(89)90041-X},
	url = {https://www.sciencedirect.com/science/article/pii/002200008990041X}
}

@InProceedings{Gupta:1994,
	author = {Prosenjit Gupta and Ravi Janardan and Michiel Smid},
	title = {Efficient Algorithms for Generalized Intersection Searching on Non-Iso-Oriented Objects},
	abstract = {Generalized intersection searching problems are a class of geometric query-retrieval problems where the questions of interest concern the intersection of a query object with aggregates of geometric objects (rather than with individual objects.) This class contains, as a special case, the well-studied class of standard intersection searching problems and is rich in applications. Unfortunately, the solutions known for the standard problems do not yield efficient solutions to the generalized problems. Recently, efficient solutions have been given for generalized problems where the input and query objects are iso-oriented (i.e., axes-parallel) or where the aggregates satisfy additional properties (e.g., connectedness). In this paper, efficient algorithms are given for several generalized problems involving non-iso-oriented objects. These problems include: generalized halfspace range searching, segment intersection searching, triangle stabbing, and triangle range searching. The techniques used include: computing suitable sparse representations of the input, persistent data structures, and filtering search.},
	keywords = {persistence, intersection searching, computational geometry, geometric duality, filtering search, data structures},
	booktitle = {Proceedings of the Tenth Annual Symposium on Computational Geometry},
	series = {SCG '94},
	year = {1994},
	pages = {369--378},
	numpages = {10},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	isbn = {0897916484},
	doi = {10.1145/177424.178096},
	url = {https://doi.org/10.1145/177424.178096}
}

@Article{Ha:1997,
	author = {Ha, T.M.},
	title = {The optimum class-selective rejection rule}, 
  	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
	year = {1997},
	volume = {19},
  	number = {6},
  	pages = {608--615},
  	doi = {10.1109/34.601248}
}

@Article{Heffernan:1995,
	author = {Paul J. Heffernan and  Joseph S. B. Mitchell},
	title = {An Optimal Algorithm for Computing Visibility in the Plane},
	abstract = {The authors give an algorithm to compute the visibility polygon from a point among a set of h pairwise-disjoint polygonal obstacles with a total of n vertices. The algorithm uses \$O(n)\$ space and runs in optimal time \$\Theta (n + h \log h)\$, improving the previous upper bound of \$O(n \log n)\$. A direct consequence of the algorithm is an \$O(n + h \log h)\$ time algorithm for computing the convex hull of h disjoint simple polygons.},
	journal = {SIAM Journal on Computing},
	volume = {24},	
	number = {1},
	year = {1995},
	pages = {184--201},
	doi = {10.1137/S0097539791221505},
	url = {https://doi.org/10.1137/S0097539791221505}
}

@Article{Heitz:2020,
	author = {Heitz, E.},
	title = {Can't Invert the CDF? The Triangle-Cut Parameterization of the Region under the Curve},
	journal = {Computer Graphics Forum},
	year = {2020},
	volume = {39},
	number = {4},
    pages = {121--132},
	doi = {https://doi.org/10.1111/cgf.14058}
}

@InProceedings{Hiller:2021,
	author = {Hiller, Michaela and Koster, Arie M. C. A. and Triesch, Eberhard},
	editor = {Gentile, Claudio and Stecca, Giuseppe and Ventura, Paolo},
	title = {On the Burning Number of p-Caterpillars},
	abstract = {The burning number is a recently introduced graph parameter indicating the spreading speed of content in a graph through its edges. While the conjectured upper bound on the necessary number of time steps until all vertices are reached is proven for some specific graph classes, it remains open for trees in general. We present two different proofs for ordinary caterpillars and prove the conjecture for a generalised version of caterpillars and for trees with a sufficient number of legs. Furthermore, determining the burning number for spider graphs, trees with maximum degree three and path-forests is known to be NP{\$}{\$}{\backslash}mathcal {\{}N{\}}{\backslash}mathcal {\{}P{\}}{\$}{\$}-complete; however, we show that the complexity is already inherent in caterpillars with maximum degree three.},
	bookTitle = {Graphs and Combinatorial Optimization: from Theory to Applications: CTW2020 Proceedings},
	year = {2021},
	pages = {145--156},
	publisher = {Springer International Publishing},
	address = {Cham},
	isbn = {978-3-030-63072-0},
	doi = {10.1007/978-3-030-63072-0_12}
}

@Article{Hochreiter:1997,
    author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
    title = {Long Short-Term Memory},
    abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
    journal = {Neural Comput.},
    year = {1997},
    volume = {9},
    number = {8},
    pages = {1735--1780},
    publisher = {MIT Press},
    address = {Cambridge, MA, USA},
    doi = {10.1162/neco.1997.9.8.1735}
}

@inproceedings{Ho:2020,
	author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
	title = {Denoising Diffusion Probabilistic Models},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
	year = {2020},
	volume = {33},
	pages = {6840--6851},
	publisher = {Curran Associates, Inc.}
}

@Article{Huang:2022,
	author = {Huang, Yu and Tang, Yufei and Zhu, Xingquan and Zhuang, Hanqi and Cherubin, Laurent},
	title = {Physics-Coupled Spatio-Temporal Active Learning for Dynamical Systems},
	journal = {IEEE Access},
  	year = {2022},
  	volume = {10},
	pages = {112909--112920},
	doi = {10.1109/ACCESS.2022.3214544}
}

@Article{Hudzik:1994,
	author = {H. Hudizk and L. Maligranda},
	title = {Some remarks on s-convex functions},
	journal = {Aequationes Mathematicae},
	year = {1994},
	volume = {48},
	pages = {100--111},
	doi = {https://doi.org/10.1007/BF01837981}
}

@Article{Hullermeier:2021,
  	title = {Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods},
  	author = {Eyke H{\"u}llermeier and Willem Waegeman},
  	journal = {Machine Learning},
  	year = {2021},
  	volume = {110},
  	pages = {457--506}
}

@Article{Ieva:2013,
	author = {Francesca Ieva and Anna M. Paganoni},
	title = {Depth Measures for Multivariate Functional Data},
	journal = {Communications in Statistics - Theory and Methods},
	year  = {2013},
	volume = {42},
	number = {7},
	pages = {1265-1276},
	publisher = {Taylor & Francis},
	doi = {10.1080/03610926.2012.746368},
	url = {https://doi.org/10.1080/03610926.2012.746368}
}

@article{Izenman:2012,
    author = {Izenman, Alan Julian},
    title = {Introduction to manifold learning},
	journal = {WIREs Comput. Stat.},
    year = {2012},
	volume = {4},
    number = {5},
	pages = {439--446},
    issue_date = {September 2012},
    publisher = {John Wiley \& Sons, Inc.},
    address = {USA},
    url = {https://doi.org/10.1002/wics.1222},
}

@InProceedings{Jaini:2020,  
	author = {Jaini, Priyank and Kobyzev, Ivan and Yu, Yaoliang and Brubaker, Marcus},
	title = {Tails of {L}ipschitz Triangular Flows},    	booktitle = {Proceedings of the 37th International Conference on Machine Learning}, 
	series = {Proceedings of Machine Learning Research},
	editor = {III, Hal Daum√© and Singh, Aarti}, 
	year = {2020},
	volume = {119},
	pages = {4673--4681},
	publisher = {Proceedings of Machine Learning Research},
	url = {https://proceedings.mlr.press/v119/jaini20a.html}
}

@InProceedings{Jiang:2017,
	author = {Zhuxi Jiang and Yin Zheng and Huachun Tan and Bangsheng Tang and Hanning Zhou},
	title = {Variational Deep Embedding: An Unsupervised and Generative Approach to Clustering},
  	booktitle = {Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, {IJCAI-17}},
  	year = {2017},
  	pages = {1965--1972},
  	doi = {10.24963/ijcai.2017/273}
}

@Article{Jones:1992,
 	author = {Lee K. Jones},
 	title = {A Simple Lemma on Greedy Approximation in Hilbert Space and Convergence Rates for Projection Pursuit Regression and Neural Network Training},
 	abstract = {A general convergence criterion for certain iterative sequences in Hilbert space is presented. For an important subclass of these sequences, estimates of the rate of convergence are given. Under very mild assumptions these results establish an $O(1/ \sqrt n)$ nonsampling convergence rate for projection pursuit regression and neural network training; where n represents the number of ridge functions, neurons or coefficients in a greedy basis expansion.},
 	journal = {The Annals of Statistics},
 	year = {1992},
 	volume = {20},
	number = {1},
 	pages = {608--613},
 	publisher = {Institute of Mathematical Statistics},
 	url = {http://www.jstor.org/stable/2242184}
}

@Article{Jones:1987,
	author = {M. C. Jones and Robin Sibson},
	title = {What is Projection Pursuit?},
 	abstract = {Friedman and Tukey (1974) introduced the term "projection pursuit" for a technique for the exploratory analysis of multivariate data sets; the method seeks out "interesting" linear projections of the multivariate data onto a line or a plane. In this paper, we show how to set Friedman and Tukey's idea in a more structured context than they offered. This makes it possible to offer some suggestions for the reformulation of the method, and thence to identify a computationally efficient approach to its implementation. We illustrate its application to empirical data, and discuss its practical attractions and limitations. Extensions by other workers to problems such as non-linear multiple regression and multivariate density estimation are discussed briefly within the same framework.},
 	journal = {Journal of the Royal Statistical Society. Series A (General)},
 	year = {1987},
 	volume = {150},
 	number = {1},
 	pages = {1--37},
 	publisher = {Royal Statistical Society, Wiley},
 	url = {http://www.jstor.org/stable/2981662}
}

@Article{Kalai:2006,
	author = {Adam Tauman Kalai and Santosh Vempala},
	title = {Simulated Annealing for Convex Optimization},
	journal = {Mathematics of Operations Research},
	year = {2006},
	volume = {31},
	number = {2},
	pages = {253--266},
	publisher = {INFORMS},
	url = {http://www.jstor.org/stable/25151723}
}

@Inproceedings{Kalra:2018,
	author = {Agastya Kalra and Abdullah Rashwan and Wei-Shou Hsu and Pascal Poupart and Prashant Doshi and Georgios Trimponias},
	title = {Online Structure Learning for Feed-Forward and Recurrent Sum-Product Networks},
 	booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
 	year = {2018},
 	volume = {32},
 	pages = {6944--6954},
 	publisher = {Curran Associates, Inc.},
 	url = {https://proceedings.neurips.cc/paper/2018/file/66121d1f782d29b62a286909165517bc-Paper.pdf},
}

@Article{Keil:2000,
	author = {Mark Keil and David M. Mount and S.K. Wismath},
	title = {Visibility Stabs and Depth-First Spiralling on Line Segments in Output Sensitive Time},
	journal = {International Journal of Computational Geometry \& Applications},
	year = {2000},
	volume = {10},
	number = {5},
	pages = {535--552}
}

@Article{Keil:1985,
	author = {Mark J. Keil},
	title = {Decomposing a Polygon into Simpler Components},
	journal = {SIAM Journal on Computing},
	year = {1985},
	volume = {14},
	number = {4},
	pages = {799--817},
	doi = {10.1137/0214056}
}

@Article{KeilsonS:1952,
	author = {Keilson, Julian and Storer, James E.},
	title = {On Brownian Motion, Boltzmann's Equation, and the Fokker-Planck Equation},
 	journal = {Quarterly of Applied Mathematics},
 	year = {1952},
 	volume = {10},
 	number = {3},
	pages = {243--253},
 	publisher = {Brown University},
 	url = {http://www.jstor.org/stable/43633965}
}

@Article{Kemppainen:2017,
	author = {Antti Kemppainen and Stanislav Smirnov},
	title = {Random curves, Scaling Limits and Lowner Evolutions},
	abstract = {In this paper, we provide a framework of estimates for describing 2D scaling limits by Schramm's SLE curves. In particular, we show that a weak estimate on the probability of an annulus crossing implies that a random curve arising from a statistical mechanics model will have scaling limits and those will be well described by Loewner evolutions with random driving forces. Interestingly, our proofs indicate that existence of a nondegenerate observable with a conformally-invariant scaling limit seems sufficient to deduce the required condition. Our paper serves as an important step in establishing the convergence of Ising and FK Ising interfaces to SLE curves; moreover, the setup is adapted to branching interface trees, conjecturally describing the full interface picture by a collection of branching SLEs.},
 	journal = {The Annals of Probability},
 	year = {2017},
 	volume = {45},
 	number = {2},
 	pages = {698--779},
 	publisher = {Institute of Mathematical Statistics},
 	issn = {00911798, 2168894X},
 	url = {http://www.jstor.org/stable/44245557}
}

@Article{Kerbl:2023,
	author = {Kerbl, Bernhard and Kopanas, Georgios and Leimk{\"u}hler, Thomas and Drettakis, George},
	title = {3D Gaussian Splatting for Real-Time Radiance Field Rendering},
    journal = {ACM Transactions on Graphics},
    year = {2023},
    number = {4},
    volume = {42},
    url = {https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/}
}

@Article{Kingma:2019,
	author = {Kingma, Diederik P. and Welling, Max},
	title = {An Introduction to Variational Autoencoders},
	journal = {Foundations and Trends¬Æ in Machine Learning},
	year = {2019},
	volume = {12},
	number = {4},
	pages = {307--392},
	doi = {10.1561/2200000056}
}

@Inproceedings{Kirkpatrick:1995,
	author = {David G. Kirkpatrick and Jack Snoeyink},
	title = {Computing Common Tangents Without a Separating Line},
	booktitle = {Proceedings of the 4th International Workshop on Algorithms and Data Structures},
	year = {1995},
	pages = {183‚Äì193},
	numpages = {11},
	series = {WADS '95},
	publisher = {Springer},
	address = {Berlin, Heidelberg},
	isbn = {3540602208}
}

@Article{Kirkpatrick:1983,
	author = {David Kirkpatrick},
	title = {Optimal Search in Planar Subdivisions},
	journal = {SIAM Journal on Computing (SICOMP)},
	year = {1983},
	month = {February},
	volume = {12},
	number = {1},
	pages = {28--35}
}

@Article{Kobyzev:2021,
	author = {Ivan Kobyzev and Simon J.D. Prince and  Marcus A. Brubaker},
  	title = {Normalizing Flows: An Introduction and Review of Current Methods}, 
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  	year = {2021},
  	volume = {43},
  	number = {11},
  	pages = {3964--3979},
  	doi = {10.1109/TPAMI.2020.2992934}
}

@inproceedings{Koltun:2001,
    author = {Koltun, Vladlen},
    title = {Segment Intersection Searching Problems in General Settings},
    abstract = {We consider segment intersection searching amidst (possibly intersecti ng) algebraic arcs in the plane. We show how to preprocess $n$ arcs in time $O(n^{2+epsilon})$ into a data structure of size $O(n^{2+epsilon})$, for any $epsilon >0$, such that the $k$ arcs intersecting a query segment can be counted in time $O(log n)$ or reported in time $O(log n+k)$. This problem was extensively studied in restricted settings (e.g., amidst segments, circles or circular arcs), but no solution with comparable performance was previously presented for the general case of possibly intersecting algebraic arcs. Our data structure for the general case matches or improves (sometimes by an order of magnitude) the size of the best previously presented solutions for the special cases.As an immediate application of this result, we obtain an efficient data structure for the triangular windowing problem, which is a generalization of triangular range searching. As another application, the first substantially sub-quadratic algorithm for a red-blue intersection counting problem is derived. We also describe simple data structures for segment intersection searching among disjoint arcs, and ray shooting among algebraic arcs.},
    booktitle = {Proceedings of the Seventeenth Annual Symposium on Computational Geometry},
    year = {2001},
    pages = {197‚Äì206},
    numpages = {10},
    publisher = {Association for Computing Machinery},
    address = {USA},
    location = {New York},
    series = {SCG '01},
    isbn = {158113357X},
    doi = {10.1145/378583.378667},
    url = {https://doi-org.uml.idm.oclc.org/10.1145/378583.378667}
}

@InProceedings{Kong:2020,
	author = {Kong, Zhifeng and Chaudhuri, Kamalika},
	title = {The Expressive Power of a Class of Normalizing Flow Models},
  	booktitle = {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  	series = {Proceedings of Machine Learning Research},
  	editor = {Chiappa, Silvia and Calandra, Roberto},
  	year = {2020},
  	volume = {108},
  	pages = {3599--3609},
  	publisher = {PMLR},
  	url = {https://proceedings.mlr.press/v108/kong20a.html}
}

@InProceedings{Koyejo:2015,
	author = {Koyejo, Oluwasanmi O and Natarajan, Nagarajan and Ravikumar, Pradeep K and Dhillon, Inderjit S},
	title = {Consistent Multilabel Classification},
 	booktitle = {Advances in Neural Information Processing Systems},
 	editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
 	year = {2015},
 	volume = {28},
 	pages = {},
 	publisher = {Curran Associates, Inc.},
	url = {https://proceedings.neurips.cc/paper/2015/file/85f007f8c50dd25f5a45fca73cad64bd-Paper.pdf} 
}

@Article{Kurtek:2012,
	author = {Sebastian Kurtek and Anuj Srivastava and Eric Klassen and Zhaohua Ding},
	title = {Statistical Modeling of Curves Using Shapes and Related Features},
	abstract = {Motivated by the problems of analyzing protein backbones, diffusion tensor magnetic resonance imaging (DT-MRI) fiber tracts in the human brain, and other problems involving curves, in this study we present some statistical models of parameterized curves, in, in terms of combinations of features such as shape, location, scale, and orientation. For each combination of interest, we identify a representation manifold, endow it with a Riemannian metric, and outline tools for computing sample statistics on these manifolds. An important characteristic of the chosen representations is that the ensuing comparison and modeling of curves is invariant to how the curves are parameterized. The nuisance variables, including parameterization, are removed by forming quotient spaces under appropriate group actions. In the case of shape analysis, the resulting spaces are quotient spaces of Hilbert spheres, and we derive certain wrapped truncated normal densities for capturing variability in observed curves. We demonstrate these models using both artificial data and real data involving DT-MRI fiber tracts from multiple subjects and protein backbones from the Shape Retrieval Contest of Non-rigid 3D Models (SHREC) 2010 database.},
	journal = {Journal of the American Statistical Association},
	year = {2012},
	volume = {107},
	number = {499},
	pages = {1152--1165},
	publisher = {Taylor \& Francis Group},
	address = {Alexandria},
	issn = {0162-1459}
}

@InProceedings{Kwon:1991,
	author={Taek Mu Kwon}, 
	title={Gaussian perceptron: experimental results}, 
	booktitle={Conference Proceedings 1991 IEEE International Conference on Systems, Man, and Cybernetics},
	year={1991},
	volume={3},
	pages={1593--1598},
	doi={10.1109/ICSMC.1991.169917}
}

@Article{Lagae:2010,
	author = {A. Lagae and S. Lefebvre and R. Cook and T. DeRose and G. Drettakis and D.S Ebert and J.P. Lewis and K. Perlin and M. Zwicker},
	title = {A Survey of Procedural Noise Functions},
	abstract = {Abstract Procedural noise functions are widely used in computer graphics, from off-line rendering in movie production to interactive video games. The ability to add complex and intricate details at low memory and authoring cost is one of its main attractions. This survey is motivated by the inherent importance of noise in graphics, the widespread use of noise in industry and the fact that many recent research developments justify the need for an up-to-date survey. Our goal is to provide both a valuable entry point into the field of procedural noise functions, as well as a comprehensive view of the field to the informed reader. In this report, we cover procedural noise functions in all their aspects. We outline recent advances in research on this topic, discussing and comparing recent and well-established methods. We first formally define procedural noise functions based on stochastic processes and then classify and review existing procedural noise functions. We discuss how procedural noise functions are used for modelling and how they are applied to surfaces. We then introduce analysis tools and apply them to evaluate and compare the major approaches to noise generation. We finally identify several directions for future work.},
	keywords = {procedural noise function, noise, stochastic process, procedural, Perlin noise, wavelet noise, anisotropic noise, sparse convolution noise, Gabor noise, spot noise, surface noise, solid noise, anti-aliasing, filtering, stochastic modelling, procedural texture, procedural modelling, solid texture, texture synthesis, spectral analysis, power spectrum estimation, I.3.3 Computer Graphics: Picture/Image Generation‚ÄîI.3.7 Computer Graphics: Three-Dimensional Graphics and Realism-Colour, shading, shadowing, and texture},
	journal = {Computer Graphics Forum},
	year = {2010},
	volume = {29},
	number = {8},
	pages = {2579--2600},
	doi = {https://doi.org/10.1111/j.1467-8659.2010.01827.x}
}

@Article{Lapin:2016,
	author = {Maksim Lapin and Matthias Hein and Bernt Schiele},
  	title = {Analysis and Optimization of Loss Functions for Multiclass, Top-k, and Multilabel Classification},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  	year = {2016},
  	volume = {40},
  	pages = {1533--1554}
}

@Article{LeCun:2015,
	author = {Y. LeCun and Y. Bengio and G. Hinton},
	title = {Deep learning},
	abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
	journal = {Nature},
	year = {2015},
	volume = {521},
	number = {7553},
	pages = {436--444}
}

@Article{Levoy:1990,
	author = {Marc Levoy},
	title = {Efficient Ray Tracing of Volume Data},
	abstract = {Volume rendering is a technique for visualizing sampled scalar or vector fields of three spatial dimensions without fitting geometric primitives to the data. A subset of these techniques generates images by computing 2-D projections of a colored semitransparent volume, where the color and opacity at each point are derived from the data using local operators. Since all voxels participate in the generation of each image, rendering time grows linearly with the size of the dataset. This paper presents a front-to-back image-order volume-rendering algorithm and discusses two techniques for improving its performance. The first technique employs a pyramid of binary volumes to encode spatial coherence present in the data, and the second technique uses an opacity threshold to adaptively terminate ray tracing. Although the actual time saved depends on the data, speedups of an order of magnitude have been observed for datasets of useful size and complexity. Examples from two applications are given: medical imaging and molecular graphics.},
	journal = {ACM Transactions on Graphics},
	year = {1990},
	volume = {9},
	number = {3},
	pages = {245--261},
	numpages = {17},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	issn = {0730-0301},
	doi = {10.1145/78964.78965},
	url = {https://doi.org/10.1145/78964.78965}
}

@InProceedings{LiLHB:2021,
	author = {Li, Yang and Si, Si and Li, Gang and Hsieh, Cho-Jui and Bengio, Samy},
	title = {Learnable Fourier Features for Multi-dimensional Spatial Positional Encoding},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
	year = {2021},
	url = {https://openreview.net/forum?id=R0h3NUMao_U}
}

@Article{Li:2022,
    author = {Li, Xia and Xu, Wei and Ren, Minglei and Jiang, Yanan and Fu, Guangtao},
    title = "{Hybrid CNN-LSTM models for river flow prediction}",
    journal = {Water Supply},
    year = {2022},
    volume = {22},
    number = {5},
    pages = {4902--4919},
    abstract = "{River flow prediction is a challenging problem due to highly nonlinear hydrological processes and high spatio-temporal variability. Here we present a hybrid network of convolutional neural network (CNN) and long short-term memory (LSTM) network for river flow prediction. The hybridization enables accurate identification of the spatial and temporal features in precipitation. A shortcut layer is used as an additional channel of passing input features through the deep network to increase feature diversity. The flows in Hun River Basin, China are predicted using the trained hybrid network and are compared with the results from the Soil and Water Assessment Tool (SWAT) model. The results demonstrate the learning efficiency of the hybrid network is greatly affected by its structure and parameters, including the number of convolutional layers and LSTM cell layers, the step size of pooling and training data size. Further, the shortcut layer can effectively solve the diversity reduction problem in a deep network. The hybrid network is shown to have a similar predictive performance to SWAT but is superior in wet seasons due to its nonlinear learning ability. This study shows that the hybrid network has great promise in learning nonlinear and high spatio-temporal variability in river flow forecasting.}",
    doi = {10.2166/ws.2022.170}
}

@InProceedings{Li:2021,
	author = {Junyi Li and Tianyi Tang and Wayne Xin Zhao and Ji-Rong Wen},
	title = {Pretrained Language Model for Text Generation: A Survey},
  	booktitle = {Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, {IJCAI-21}},
  	editor = {Zhi-Hua Zhou},
  	pages = {4492--4499},
  	year = {2021},
  	publisher = {International Joint Conferences on Artificial Intelligence Organization},
  	doi = {10.24963/ijcai.2021/612}
}

@Article{Liu:1999,
	author = {Regina Y. Liu and Jesse M. Parelius and Kesar Singh},
	title = {Multivariate Analysis by Data Depth: Descriptive Statistics, Graphics and Inference},
	journal = {The Annals of Statistics},
	year = {1999},
	volume = {27},
 	number = {3},
 	pages = {783--840}, 
 	publisher = {Institute of Mathematical Statistics},
 	URL = {http://www.jstor.org/stable/120138}
}

@InProceedings{Lou:2023,
 	author = {Lou, Aaron and Ermon, Stefano},
 	title = {Reflected Diffusion Models},
 	booktitle = {Proceedings of the 40th International Conference on Machine Learning},
 	series = {Proceedings of Machine Learning Research},
  	editor = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
	year = {2023},
  	volume = {202},
  	pages = {22675--22701},
  	publisher = {{PMLR}},
  	url = {https://proceedings.mlr.press/v202/lou23a.html}
}

@InProceedings{Louis:2023,
	author = {Grenioux, Louis and Oliviero Durmus, Alain and Moulines, Eric and Gabri\'{e}, Marylou},
  	title = {On Sampling with Approximate Transport Maps},
  	booktitle = {Proceedings of the 40th International Conference on Machine Learning},
  	series = {Proceedings of Machine Learning Research},
  	editor = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  	year = {2023},
  	volume = {202},
  	pages = {11698--11733},
  	publisher = {PMLR},
  	url = {https://proceedings.mlr.press/v202/grenioux23a.html}
}

@InProceedings{Lu:2023,
	author = {Haoye Lu and Yiwei Lu and Dihong Jiang and Spencer Ryan Szabados and Sun Sun and Yaoliang Yu},
	title = {{CM}-{GAN}: Stabilizing {GAN} Training with Consistency Models},
	booktitle = {ICML 2023 Workshop on Structured Probabilistic Inference {\&} Generative Modeling},
	year = {2023},
	url = {https://openreview.net/forum?id=Uh2WwUyiAv}
}

@Article{Ma:2019,
	author = {Ma, Yi-An  and Chen, Yuansi  and Jin, Chi and Flammarion, Nicolas and Jordan, Michael I.},
	title = {Sampling can be faster than optimization},
	journal = {Proceedings of the National Academy of Sciences},
	year = {2019},
	volume = {116},
	number = {42},
	pages = {20881--20885},
	doi = {10.1073/pnas.1820003116}
}

@Article{Ma:2021,
	author = {Liyao Ma and Thierry Den≈ìux},
	title = {Partial classification in the belief function framework},
	keywords = {Dempster‚ÄìShafer theory, Evidence theory, Supervised classification, Decision-making, Set-valued classification, OWA operator},
	journal = {Knowledge-Based Systems},
	year = {2021},
	volume = {214},
	pages = {106742},
	doi = {https://doi.org/10.1016/j.knosys.2021.106742}
}

@Article{Micheaux:2021,
	author = {Pierre Lafaye de Micheaux and Pavlo Mozharovskyi and Myriam Vimond},
	title = {Depth for Curve Data and Applications},
	journal = {Journal of the American Statistical Association},
	year  = {2021},
	volume = {116},
	number = {536},
	pages = {1881-1897},
	publisher = {Taylor & Francis},
	doi = {10.1080/01621459.2020.1745815},
	url = {https://doi.org/10.1080/01621459.2020.1745815}
}

@Article{Mitchell:1991,
	author = {Joseph S.B. Mitchell},
	title = {A New Algorithm for Shortest Paths Among Obstacles in the Plane},
	journal = {Annals of Mathematics and Artificial Intelligence},
	year = {1991},
	volume = {3},
	pages = {83--106}
}

@Inproceedings{Mikolov:2010,
	author = {Mikolov, Tom√°≈° and Karafi√°t, Martin and Burget, Luk√°≈° and ƒåernock√Ω, Jan and Khudanpur, Sanjeev},
  	title = {Recurrent neural network based language model},
  	booktitle = {Proceedings of Interspeech 2010},
  	year = {2010},
  	pages = {1045--1048},
    doi = {10.21437/Interspeech.2010-343}
}

@InProceedings{Mortier:2022,
	author = {Thomas Mortier and Krzysztof Dembczynski and Eyke H{\"u}llermeier and Willem Waegeman},
	title = {Set-valued prediction in hierarchical classification with constrained representation complexity},
	booktitle = {Proceedings of the 38th Conference on Uncertainty in Artificial Intelligence},
	year = {2022},
	volume = {180},
	pages = {1392--1401},
	url = {https://openreview.net/forum?id=rY8NwwLoceq}
}

@Article{Mortier:2021,
	author = {Mortier, Thomas and Wydmuch, Marek and Dembczy\'{n}ski, Krzysztof and H\"{u}llermeier, Eyke and Waegeman, Willem},
    title = {Efficient Set-Valued Prediction in Multi-Class Classification},
    journal = {Data Min. Knowl. Discov.},
    year = {2021},
    volume = {35},
    number = {4},
    pages = {1435--1469},
    numpages = {35},
    publisher = {Kluwer Academic Publishers},
    address = {USA},
    doi = {10.1007/s10618-021-00751-x}
}

@Unpublished{Mozharovskyi:2022,
	author = {Pavlo Mozharovskyi},
    title = {Anomaly detection using data depth: multivariate case},
    year = {2022},
	eprint = {2210.02851},
	archivePrefix = {arXiv},
    primaryClass = {stat.ML}
}

@Article{Mulmuely:1992,
    author = {Ketan Mulmuley and Sandeep Sen},
    title = {Dynamic Point Location in Arrangements of Hyperplanes.},
    journal = {Discrete \& computational geometry},
    volume = {8},
    pages = {335--360},
    year = {1992}
}

@InProceedings{Nacer:2001,
    author = {Nacer, F.-Z.N. and Zergainoh, A. and Merigot, A.},
    title = {Global discrete cosine transform for image compression}, 
    booktitle = {Proceedings of the Sixth International Symposium on Signal Processing and its Applications}, 
    year = {2001},
    volume = {2},
    pages = {545--548},
    doi = {10.1109/ISSPA.2001.950201}
}

@InProceedings{Naplava:2021,
	author = {N{\'a}plava, Jakub and Popel, Martin and Straka, Milan and Strakov{\'a}, Jana},
    title = {Understanding Model Robustness to User-generated Noisy Texts},
    booktitle = {Proceedings of the Seventh Workshop on Noisy User-generated Text (W-NUT 2021)},
    year = {2021},
    pages = {340--350},
    publisher = {Association for Computational Linguistics},
    doi = {10.18653/v1/2021.wnut-1.38}
}

@Inproceedings{Narodytska:2018,
	author = {Nina Narodytska},
	title = {Formal Verification of Deep Neural Networks}, 
  	booktitle = {2018 Formal Methods in Computer Aided Design (FMCAD)}, 
  	year = {2018},
   	pages = {1--1},
	doi={10.23919/FMCAD.2018.8603017}
}

@Inproceedings{Nath:2015, 
	author = {Aniruddh Nath and Pedro Domingos},
	title = {Learning Relational Sum-Product Networks}, 
	abstract = {Sum-product networks (SPNs) are a recently-proposed deep architecture that guarantees tractable inference, even on certain high-treewidth models. SPNs are a propositional architecture, treating the instances as independent and identically distributed. In this paper, we introduce Relational Sum-Product Networks (RSPNs), a new tractable first-order probabilistic architecture. RSPNs generalize SPNs by modeling a set of instances jointly, allowing them to influence each other‚Äôs probability distributions, as well as modeling probabilities of relations between objects. We also present LearnRSPN, the first algorithm for learning high-treewidth tractable statistical relational models. LearnRSPN is a recursive top-down structure learning algorithm for RSPNs, based on Gens and Domingos‚Äô LearnSPN algorithm for propositional SPN learning. We evaluate the algorithm on three datasets; the RSPN learning algorithm outperforms Markov Logic Networks in both running time and predictive accuracy.},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence}, 		
	year = {2015},
	volume = {29},
	number = {1},
	pages = {2878--2886},
	doi = {10.1609/aaai.v29i1.9538}
}

@Unpublished{Omohundro:1990,
	author = {Stephen M. Omohundro},
	title = {Floyed-Steinberg Dithering},
	year = {1990},
	organization = {International Computer Science Institute},
	address = {Berkeley, California}
}

@inproceedings{Ostromoukhov:2001,
	author = {Victor Ostromoukhov},
    title = {A Simple and Efficient Error-Diffusion Algorithm},
    booktitle = {Proceedings of the 28th Annual Conference on Computer Graphics and Interactive Techniques},
    series = {SIGGRAPH '01},
    year = {2001},
    pages = {567--572},
    numpages = {6},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    doi = {10.1145/383259.383326}
}

@InProceedings{Pagh:2005,
	author = {Pagh, Anna and Pagh, Rasmus and Rao, S. Srinivasa},
	title = {An Optimal Bloom Filter Replacement},
	booktitle = {Proceedings of the Sixteenth Annual ACM-SIAM Symposium on Discrete Algorithms},
	series = {SODA '05},
	year = {2005},
	pages = {823--829},
	numpages = {7},
	publisher = {Society for Industrial and Applied Mathematics},
	address = {USA}
}

@Article{Parzen:1962,
	author = {Parzen, Emanuel},
	title = {On Estimation of a Probability Density Function and Mode},
	journal = {The Annals of Mathematical Statistics},
	year = {1962},
	volume = {33},
	number = {3},
	pages = {1065--1076},
	publisher = {Institute of Mathematical Statistics},
	doi = {10.1214/aoms/1177704472}
}

@InProceedings{Peharz:2020,
	author = {Robert Peharz and Antonio Vergari and Karl Stelzner and Alejandro Molina and Xiaoting Shao and Martin Trapp and Kristian Kersting and Zoubin Ghahramani},
	title = {Random Sum-Product Networks: A Simple and Effective Approach to Probabilistic Deep Learning},
	booktitle = {Proceedings of The 35th Uncertainty in Artificial Intelligence Conference},
  	series = {Proceedings of Machine Learning Research},
  	editor = {Ryan P. Adams and Vibhav Gogate},
  	year = {2020},
  	volume = {115},
  	pages = {334--344},
  	publisher = {PMLR},
  	url = {https://proceedings.mlr.press/v115/peharz20a.html}
}

@InProceedings{Peharz:2014,
	author = {Robert Peharz and Georg Kapeller and Pejman Mowlaee and Franz Pernkopf},
	title = {Modeling speech with sum-product networks: Application to bandwidth extension}, 
	booktitle = {2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  	year = {2014},
  	pages = {3699--3703},
	doi = {10.1109/ICASSP.2014.6854292}
}

@Unpublished{Perlin:2002,
    title = {Improving noise},
    author = {Ken Perlin},
    journal = {Proceedings of the 29th annual conference on Computer graphics and interactive techniques},
    year = {2002},
    url = {https://mrl.cs.nyu.edu/~perlin/paper445.pdf}
}

@Inproceedings{Perlin:1989,
	author = {K. Perlin and E. M. Hoffert},
	title = {Hypertexture},
	abstract = {We model phenomena intermediate between shape and texture by using space-filling applicative functions to modulate density. The model is essentially an extension of procedural solid texture synthesis, but evaluated throughout a volumetric region instead of only at surfaces.We have been able to obtain visually realistic representations of such shape+texture (hypertexture) phenomena as hair, fur, fire, glass, fluid flow and erosion effects. We show how this is done, first by describing a set of base level functions to provide basic texture and control capability, then by combining these to synthesize various phenomena.Hypertexture exists within an intermediate region between object and not-object. We introduce a notion of generalized boolean shape operators to combine shapes having such a region.Rendering is accomplished by ray marching from the eye point through the volume to accumulate opacity along each ray. We have implemented our hypertexture rendering algorithms on a traditional serial computer, a distributed network of computers and a coarse-grain MIMD computer. Extensions to the rendering technique incorporating refraction and reflection effects are discussed.},
	booktitle = {Proceedings of the 16th Annual Conference on Computer Graphics and Interactive Techniques},
	series = {SIGGRAPH '89},
	year = {1989},
	pages = {253--262},
	numpages = {10},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	isbn = {0897913124},
	url = {https://doi.org/10.1145/74333.74359},
	doi = {10.1145/74333.74359}
}

@Inproceedings{Perlin:1985,
	author = {Ken Perlin},
	title = {An Image Synthesizer},
	abstract = {We introduce the concept of a Pixel Stream Editor. This forms the basis for an interactive synthesizer for designing highly realistic Computer Generated Imagery. The designer works in an interactive Very High Level programming environment which provides a very fast concept/implement/view iteration cycle.Naturalistic visual complexity is built up by composition of non-linear functions, as opposed to the more conventional texture mapping or growth model algorithms. Powerful primitives are included for creating controlled stochastic effects. We introduce the concept of "solid texture" to the field of CGI.We have used this system to create very convincing representations of clouds, fire, water, stars, marble, wood, rock, soap films and crystal. The algorithms created with this paradigm are generally extremely fast, highly realistic, and asynchronously parallelizable at the pixel level.},
	keywords = {fire, turbulence, waves, space function, functional composition, stochastic modelling, interactive, solid texture, pixel stream editor, algorithm development},
	booktitle = {Proceedings of the 12th Annual Conference on Computer Graphics and Interactive Techniques},
	series = {SIGGRAPH '85},
	year = {1985},
	pages = {287--296},
	numpages = {10},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	doi = {10.1145/325334.325247}
}

@Article{Peyre:2019,
	author = {Gabriel Peyr\‚Äôe and Marco Cuturi},
	title = {Computational Optimal Transport},
	journal = {Foundations and Trends in Machine Learning},
	year = {2019},
	volume = {11},
	number = {5-6},
	pages = {355--607}
}

@Article{Phong:1975,
	author = {Bui Tuong Phong},
	title = {Illumination for Computer Generated Pictures},
	abstract = {The quality of computer generated images of three-dimensional scenes depends on the shading technique used to paint the objects on the cathode-ray tube screen. The shading algorithm itself depends in part on the method for modeling the object, which also determines the hidden surface algorithm. The various methods of object modeling, shading, and hidden surface removal are thus strongly interconnected. Several shading techniques corresponding to different methods of object modeling and the related hidden surface algorithms are presented here. Human visual perception and the fundamental laws of optics are considered in the development of a shading rule that provides better quality and increased realism in generated images.},
	keywords = {shading, hidden surface removal, computer graphics, graphic display},
	journal = {Communications of the ACM},
	year = {1975},
	volume = {18},
	number = {6},
	pages = {311--317},
	numpages = {7},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	issn = {0001-0782},
	doi = {10.1145/360825.360839},
	url = {https://doi.org/10.1145/360825.360839}
}

@Article{Pintado:2014,
	author = {Sara L√≥pez-Pintado and Ying Sun and Juan k. Lin and Marc G. Genton},
	title = {Simplicial band depth for multivariate functional data},
	abstract = {We propose notions of simplicial band depth for multivariate functional data that extend the univariate functional band depth. The proposed simplicial band depths provide simple and natural criteria to measure the centrality of a trajectory within a sample of curves. Based on these depths, a sample of multivariate curves can be ordered from the center outward and order statistics can be defined. Properties of the proposed depths, such as invariance and consistency, can be established. A simulation study shows the robustness of this new definition of depth and the advantages of using a multivariate depth versus the marginal depths for detecting outliers. Real data examples from growth curves and signature data are used to illustrate the performance and usefulness of the proposed depths.},
	journal = {Advances in data analysis and classification},
	year = {2014},
	volume = {8},
	number = {3},
	pages = {321--338},
	publisher = {Springer},
	address = {Berlin, Heidelberg},
	issn = {1862-5347}
}

@Article{Pintado:2009,
	author = {Sara L√≥pez-Pintado and Juan Romo},
	title = {On the Concept of Depth for Functional Data},
	abstract = {The statistical analysis of functional data is a growing need in many research areas. In particular, a robust methodology is important to study curves, which are the output of many experiments in applied statistics. As a starting point for this robust analysis, we propose, analyze, and apply a new definition of depth for functional observations based on the graphic representation of the curves. Given a collection of functions, it establishes the "centrality" of an observation and provides a natural center-outward ordering of the sample curves. Robust statistics, such as the median function or a trimmed mean function, can be defined from this depth definition. Its finite-dimensional version provides a new depth for multivariate data that is computationally feasible and useful for studying high-dimensional observations. Thus, this new depth is also suitable for complex observations such as microarray data, images, and those arising in some recent marketing and financial studies. Natural properties of these new concepts are established and the uniform consistency of the sample depth is proved. Simulation results show that the corresponding depth based trimmed mean presents better performance than other possible location estimators proposed in the literature for some contaminated models. Data depth can be also used to screen for outliers. The ability of the new notions of depth to detect "shape" outliers is presented. Several real datasets are considered to illustrate this new concept of depth, including applications to microarray observations, weather data, and growth curves. Finally, through this depth, we generalize to functions the Wilcoxon rank sum test. It allows testing whether two groups of curves come from the same population. This functional rank test when applied to children growth curves shows different growth patterns for boys and girls.},
	journal = {Journal of the American Statistical Association},
	year = {2009},
	volume = {104},
	number = {486},
	pages = {718--734},
	publisher = {American Statistical Association, Taylor \& Francis, Ltd.},
	ISSN = {01621459},
	urldate = {2022-04-04},
	url = {http://www.jstor.org/stable/40592217}
}

@Inproceedings{Pintado:2003,
    author = {Sara L{\'{o}}pez-Pintado and Juan Romo},
    editor = {Regina Y. Liu and Robert Serfling and Diane L. Souvaine},
    title = {Depth-based classification for functional data},
    booktitle = {Data Depth: Robust Multivariate Analysis, Computational Geometry and Applications, Proceedings of a {DIMACS} Workshop, New Brunswick, New Jersey, USA, May 14-16, 2003},
    series = {{DIMACS} Series in Discrete Mathematics and Theoretical Computer Science},
    volume = {72},
    pages = {103--119},
    year = {2003},
    publisher = {{DIMACS/AMS}},
    doi = {10.1090/dimacs/072/08},
    url = {https://doi.org/10.1090/dimacs/072/08},
    timestamp = {Tue, 16 Jul 2019 17:45:06 +0200},
    biburl = {https://dblp.org/rec/conf/dimacs/Lopez-PintadoR03.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{Poon:2011,
	author = {Hoifung Poon and Pedro Domingos},
	title = {Sum-product networks: A new deep architecture}, 
	booktitle = {2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops)}, 
	year = {2011},
  	pages = {689--690}
}

@InProceedings{Raginsky:2017,
	author = {Raginsky, Maxim and Rakhlin, Alexander and Telgarsky, Matus},
	title = {Non-convex learning via Stochastic Gradient Langevin Dynamics: a nonasymptotic analysis},
	booktitle = {Proceedings of the 2017 Conference on Learning Theory},
	series = {Proceedings of Machine Learning Research},
	editor = {Kale, Satyen and Shamir, Ohad},
	year = {2017},
	volume = {65},
	pages = {1674--1703},
	publisher = {PMLR},
	url = {https://proceedings.mlr.press/v65/raginsky17a.html}
}

@Article{Raid:2014,
	author = {Raid, A.M. and Khedr, W.M. and El-dosuky, M.A. and Ahmed, Wesam},
	title = {Jpeg Image Compression Using Discrete Cosine Transformation - A Survey},
	journal = {International Journal of Computer Science & Engineering Survey (IJCSES)},
	year = {2014},
	volume = {5},
	number = {2}, 
	pages = {39--47}
}

@Article{Ramsay:2021,
  	author = {Kelly Ramsay and Stephane Durocher and Alexandre Leblanc},
  	title = {Robustness and asymptotics of the projection median},
  	keywords = {Asymptotic distribution; Influence function; Multivariate median},
  	journal = {Journal of Multivariate Analysis},
  	year = {2021},
  	volume = {181},
 	pages = {104678},
 	doi = {10.1016/j.jmva.2020.10467},
  	url = {https://ideas.repec.org/a/eee/jmvana/v181y2021ics0047259x20302591.html}
}

@Article{Reyes:2016,
	author = {Alicia Nieto-Reyes and Heather Battey},
	title = {A Topologically Valid Definition of Depth for Functional Data},
	keywords = {functional data, multivariate statistics, partial observability, robustness, Statistical depth},
	journal = {Statistical Science},
	year = {2016},
	volume = {31},
	number = {1},
	pages = {61 -- 79},
	publisher = {Institute of Mathematical Statistics},
	doi = {10.1214/15-STS532}
}

@Article{Reynolds:1987,
	author = {Craig W. Reynolds},
	title = {Flocks, Herds and Schools: A Distributed Behavioral Model},
	abstract = {The aggregate motion of a flock of birds, a herd of land animals, or a school of fish is a beautiful and familiar part of the natural world. But this type of complex motion is rarely seen in computer animation. This paper explores an approach based on simulation as an alternative to scripting the paths of each bird individually. The simulated flock is an elaboration of a particle systems, with the simulated birds being the particles. The aggregate motion of the simulated flock is created by a distributed behavioral model much like that at work in a natural flock; the birds choose their own course. Each simulated bird is implemented as an independent actor that navigates according to its local perception of the dynamic environment, the laws of simulated physics that rule its motion, and a set of behaviors programmed into it by the "animator." The aggregate motion of the simulated flock is the result of the dense interaction of the relatively simple behaviors of the individual simulated birds.},
	journal = {SIGGRAPH Comput. Graph.},
	year = {1987},
	volume = {21},
	number = {4},
	pages = {25--34},
	numpages = {10},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	issn = {0097-8930},
	doi = {10.1145/37402.37406}
}

@Article{Roberts:1997,
	author = {G. O. Roberts and S. K. Sahu},
	title = {Updating Schemes, Correlation Structure, Blocking and Parameterization for the Gibbs Sampler},
 	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
 	year = {1997},
 	volume = {59},
 	number = {2},
 	pages = {291--317},
 	publisher = {[Royal Statistical Society, Wiley]},
	url = {http://www.jstor.org/stable/2346048}
}

@Article{Roberts:1992,
	author = {Roberts, Gareth O. and Polson, Nicholas G.},
	title = {On the Geometric Convergence of the Gibbs Sampler},
 	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
 	year = {1994},
 	volume = {56},
 	number = {2},
 	pages = {377--384},
 	publisher = {[Royal Statistical Society, Wiley]},
 	url = {http://www.jstor.org/stable/2345908},
}

@Article{ORourke:1998,
	author = {Joseph O'Rourke and Ileana Streinu},
	title = {The vertex-edge visibility graph of a polygon},
	abstract = {We introduce a new polygon visibility graph, the vertex-edge visibility graph GVE, and demonstrate that it encodes more geometric information about the polygon than does the vertex visibility graph GV.},
	keywords = {Visibility graphs, Visibility complex},
	journal = {Computational Geometry},
	year = {1998},
	volume = {10},
	number = {2},
	pages = {105--120},
	doi = {https://doi.org/10.1016/S0925-7721(97)00011-4}
}

@Article{ORourke:1982,
	author = {Joseph O'Rourke and Chi-Bin Chien and Thomas Olson and David Naddor},
	title = {A new linear algorithm for intersecting convex polygons},
	abstract = {An algorithm is presented that computes the intersection of two convex polygons in linear time. The algorithm is fundamentally different from the only known linear algorithms for this problem, due to Shamos and Hoey. These algorithms depend on a division of the plane into either angular sectors (Shamos) or parallel slabs (Hoey), and are mildly complex. Our algorithm searches for the intersection points of the polygons by adbancing a single pointer around each polygon, and is very easy to program.},
	journal = {Computer Graphics and Image Processing},
	year = {1982},
	volume = {19},
	number = {4},
	pages = {384--391},
	doi = {https://doi.org/10.1016/0146-664X(82)90023-5}
}

@Article{Ryff:1970,
	author = {John V Ryff},
	title = {Measure preserving transformations and rearrangements},
	journal = {Journal of Mathematical Analysis and Applications},
	year = {1970},
	volume = {31},
	number = {2},
	pages = {449--458},
	doi = {https://doi.org/10.1016/0022-247X(70)90038-7}
}

@InProceedings{Salmona:2022,
	author = {Antoine Salmona and Valentin De Bortoli and Julie Delon and Agn{\`e}s Desolneux},
	title = {Can Push-forward Generative Models Fit Multimodal Distributions?},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
	year = {2022},
	url = {https://openreview.net/forum?id=Tsy9WCO_fK1}
}

@InProceedings{Salzman:2011,
	author = {Salzman, Oren and Hemmer, Michael and Raveh, Barak and Halperin, Dan},	
	title = {Motion Planning via Manifold Samples},
	booktitle = {Proceedings of European Symposium on Algorithms (ESA '11)},
	year = {2011},
	pages = {493--505},
}

@Article{Samworth:2018,
	author = {Samworth, Richard J.},
	title = {Recent Progress in Log-Concave Density Estimation},
	year = {2018},
	volume = {33},
	number = {4},
	pages = {493--509},
	journal = {Statistical Science},	
	publisher = {Institute of Mathematical Statistics},
	doi = {10.1214/18-STS666}
}

@Article{Schultz:2021,
	author = {Schultz, M. G.  and Betancourt, C.  and Gong, B.  and Kleinert, F.  and Langguth, M.  and Leufen, L. H.  and Mozaffari, A.  and Stadtler, S. },
	title = {Can deep learning beat numerical weather prediction?},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	year = {2021},
	volume = {379},
	number = {2194},
	pages = {20200097},
	doi = {10.1098/rsta.2020.0097}
}

@Inproceedings{Serfling:2003,
	author = {Robert Serfling},
	title  = {Depth Functions in Nonparametric Multivariate Inference},
	booktitle = {Data Depth: Robust Multivariate Analysis, Computational Geometry and Applications, Proceedings of a {DIMACS} Workshop},
	editor = {Regina Y. Liu and Robert Serfling and Diane L. Souvaine},
	series = {{DIMACS} Series in Discrete Mathematics and Theoretical Computer Science},
	year = {2003},
	volume = {72},
	pages = {1--16},
	publisher = {{DIMACS/AMS}}
}

@InProceedings{Song:2023,
	author = {Song, Yang and Dhariwal, Prafulla and Chen, Mark and Sutskever, Ilya},
	title = {Consistency Models},
	booktitle = 	{Proceedings of the 40th International Conference on Machine Learning},
	editor = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
	series = {Proceedings of Machine Learning Research},
	year = {2023},
	volume = {202},
  	pages = {32211--32252},
  	publisher = {PMLR},
  	url = {https://proceedings.mlr.press/v202/song23a.html}
}

@InProceedings{Song:2020,
	author = {Song, Yang and Ermon, Stefano},
	title = {Improved Techniques for Training Score-Based Generative Models},
 	booktitle = {Advances in Neural Information Processing Systems},
 	series = {NIPS'20},
 	editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 	year = {2020},
 	volume = {33},
 	pages = {12438--12448},
 	publisher = {Curran Associates, Inc.},
 	url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/92c3b916311a5517d9290576e3ea37ad-Paper.pdf}
}


@Article{Specht:1990,
	author = {Donald F. Specht},
	title = {Probabilistic neural networks},
	abstract = {By replacing the sigmoid activation function often used in neural networks with an exponential function, a probabilistic neural network (PNN) that can compute nonlinear decision boundaries which approach the Bayes optimal is formed. Alternate activation functions having similar properties are also discussed. A fourlayer neural network of the type proposed can map any input pattern to any number of classifications. The decision boundaries can be modified in real-time using new data as they become available, and can be implemented using artificial hardware ‚Äúneurons‚Äù that operate entirely in parallel. Provision is also made for estimating the probability and reliability of a classification as well as making the decision. The technique offers a tremendous speed advantage for problems in which the incremental adaptation time of back propagation is a significant fraction of the total computation time. For one application, the PNN paradigm was 200,000 times faster than back-propagation.},
	journal = {Neural Networks},
	year = {1990},
	volume = {3},
	number = {1},
	pages = {109--118},
	doi = {https://doi.org/10.1016/0893-6080(90)90049-Q}
}

@Article{Specht:1988,
	author = {Donald F. Specht},
	title = {Probabilistic neural networks for classification, mapping, or associative memory},
  	journal = {IEEE 1988 International Conference on Neural Networks},
	year = {1988},
	volume = {1},
	pages = {525--532}
}

@Article{Staniforth:1991,
	author = {Staniforth, Andrew and C√¥t√©, Jean},
    title = {Semi-Lagrangian Integration Schemes for Atmospheric Models-A Review},
    journal = {Monthly Weather Review},
    year = {1991},
    volume = {119},
    number = {9},
    pages = {2206--2223},
    publisher = {American Meteorological Society},
    address = {Boston MA, USA},
    doi = {https://doi.org/10.1175/1520-0493(1991)119<2206:SLISFA>2.0.CO;2}
}

@InProceedings{Stroock:1972,
	author = {Stroock, Daniel W. and Varadhan, S.R.S},
	title = {Diffusion Processes},
	journal = {Berkeley Symp. on Math. Statist. and Prob.},
	year = {1972},
	volume = {3},
	pages = {361--368}
}	

@Inproceedings{Sundermeyer:2013,
	author = {Sundermeyer, M. and Oparin, I. and Gauvain, J.-L. and Freiberg, B. and Schl√ºter, R. and Ney, H.},
	title = {Comparison of feedforward and recurrent neural network language models},
	booktitle = {2013 IEEE International Conference on Acoustics, Speech and Signal Processing}, 
  	year = {2013},
  	pages = {8430--8434},
  	doi = {10.1109/ICASSP.2013.6639310}
}

@InProceedings{Suri:1986,
	author = {Subhash Suri and Joseph O'Rourke},
	title = {Worst-Case Optimal Algorithms for Constructing Visibility Polygons with Holes},
	booktitle = {Proceedings of the Second Annual Symposium on Computational Geometry},
	series = {SCG '86},
	year = {1986},
	pages = {14--23},
	numpages = {10},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	isbn = {0897911946},
	url = {https://doi.org/10.1145/10515.10517},
	doi = {10.1145/10515.10517}
}

@Article{Szirmay-Kalos:1998,
	author = {L. Szirmay-Kalos and G. M\'arton},
	title = {Worst-Case Versus Average Case Complexity of Ray-Shooting},
	journal = {Computing},
	year = {1998},
	volume = {61},
	pages = {103--131}
}

@Article{Tao:2021,
	author = {Yaguang Tao, Alan Both, Rodrigo I. Silveira, Kevin Buchin, Stef Sijben, Ross S. Purves, Patrick Laube, Dongliang Peng, Kevin Toohey, and Matt Duckham},
	title = {A comparative analysis of trajectory similarity measures},
	journal = {GIScience \& Remote Sensing},
	volume = {58},
	number = {5},
	pages = {643-669},
	year  = {2021},
	publisher = {Taylor & Francis},
	doi = {10.1080/15481603.2021.1908927},
	URL = {https://doi.org/10.1080/15481603.2021.1908927}
}

@InProceedings{Tan:2019,
	title = {Hierarchical Decompositional Mixtures of Variational Autoencoders},
	author = {Tan, Ping Liang and Peharz, Robert},
  	booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  	series = {Proceedings of Machine Learning Research},
  	editor = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  	year = {2019},
  	volume = {97},
  	pages = {6115--6124},
  	publisher = {Proceedings of Machine Learning Research},
  	url = {https://proceedings.mlr.press/v97/tan19b.html}
}

@InProceedings{Tancik:2020,
	author = {Tancik, Matthew and Srinivasan, Pratul and Mildenhall, Ben and Fridovich-Keil, Sara and Raghavan, Nithin and Singhal, Utkarsh and Ramamoorthi, Ravi and Barron, Jonathan and Ng, Ren},
	title = {Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains},
 	booktitle = {Advances in Neural Information Processing Systems},
 	editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 	year = {2020},
 	volume = {33},
 	pages = {7537--7547},
 	publisher = {Curran Associates, Inc.},
 	url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/55053683268957697aa39fba6f231c68-Paper.pdf}
}

@Article{Tjoa:2020,
	author = {Erico Tjoa and Cuntai Guan},	
	title = {A Survey on Explainable Artificial Intelligence (XAI): Toward Medical XAI},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	year = {2020},
	volume = {32},  
	number = {11}, 
	pages = {4793--4813},
	doi = {10.1109/tnnls.2020.3027314},
	url = {https://doi.org/10.1109%2Ftnnls.2020.3027314}
}

@Article{Tong:2021,
	author = {Zheng Tong and Philippe Xu and Thierry Den≈ìux},
	title = {An evidential classifier based on Dempster-Shafer theory and deep learning},
	abstract = {We propose a new classifier based on Dempster-Shafer (DS) theory and a convolutional neural network (CNN) architecture for set-valued classification. In this classifier, called the evidential deep-learning classifier, convolutional and pooling layers first extract high-dimensional features from input data. The features are then converted into mass functions and aggregated by Dempster‚Äôs rule in a DS layer. Finally, an expected utility layer performs set-valued classification based on mass functions. We propose an end-to-end learning strategy for jointly updating the network parameters. Additionally, an approach for selecting partial multi-class acts is proposed. Experiments on image recognition, signal processing, and semantic-relationship classification tasks demonstrate that the proposed combination of deep CNN, DS layer, and expected utility layer makes it possible to improve classification accuracy and to make cautious decisions by assigning confusing patterns to multi-class sets.},
	journal = {Neurocomputing},
	volume = {450},
	pages = {275--293},
	year = {2021},
	doi = {https://doi.org/10.1016/j.neucom.2021.03.066}
}

@Inproceedings{Ulichney:1993,
	author = {Robert A. Ulichney},
	title = {The Void-and-cluster method for dither array generation},
	booktitle = {Human Vision, Visual Processing, and Digital Display IV},
	year = {1993},
	volume = {1913},
	pages = {332--343},
	editor = {Jan P. Allebach and Bernice E. Rogowitz},
	organization = {International Society for Optics and Photonics},
	publisher = {SPIE},
	doi = {10.1117/12.152707},
	url = {https://doi.org/10.1117/12.152707}
}

@Article{Ulichney:1988,
	author = {Robert A. Ulichney},
	title = {Dithering with blue noise}, 
  	journal = {Proceedings of the IEEE}, 
	year = {1988},
	volume = {76},
	number = {1},
	pages = {56--79},
	doi = {10.1109/5.3288}
}

@InProceedings{Varol:2012,
	author = {Varol, Aydin and Salzmann, Mathieu and Fua, Pascal and Urtasun, Raquel},
	title = {A constrained latent variable model}, 
  	booktitle = {IEEE Conference on Computer Vision and Pattern Recognition}, 
	year = {2012},
  	pages = {2248--2255},
	doi = {10.1109/CVPR.2012.6247934}
}

@Inproceedings{Vaswani:2017,
	author = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and {\L}ukasz Kaiser and Illia Polosukhin},
	title = {Attention is All you Need},
 	booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
 	editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 	series = {NIPS'17},
 	year = {2017},
 	volume = {31},
 	pages = {6000--6010},
 	publisher = {Curran Associates, Inc.},
 	url = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}
}

@Misc{Velez:2017,
	author = {Finale Doshi-Velez and Been Kim},
	title = {Towards A Rigorous Science of Interpretable Machine Learning},
	keywords = {Machine Learning (stat.ML), Artificial Intelligence (cs.AI), 	Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
	publisher = {arXiv},  
	year = {2017},
	doi = {10.48550/ARXIV.1702.08608}
}

@Article{Vergari:2019,
	author = {Antonio Vergari and Nicola Di Mauro and Floriana Esposito},
	title = {Visualizing and understanding Sum Product Networks},
	journal = {Machine Learning},
	year = {2019},
	volume = {108},
	pages = {551--573},
	doi = {10.1007/s10994-018-5760-y}
}

@InProceedings{Volker:2019,
 	author = {Voelker, Aaron and Kaji\'{c}, Ivana and Eliasmith, Chris},
 	title = {Legendre Memory Units: Continuous-Time Representation in Recurrent Neural Networks},
 	booktitle = {Advances in Neural Information Processing Systems},
 	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 	year = {2019},
 	volume = {32},
 	pages = {},
 	publisher = {Curran Associates, Inc.},
 	url = {https://proceedings.neurips.cc/paper/2019/file/952285b9b7e7a1be5aa7849f32ffff05-Paper.pdf}
}

@InProceedings{Wiratma:2017,
	author = {Lionov Wiratma and Marc van Kreveld and Maarten L{\"o}ffler},
	title = {On Measures for Groups of Trajectories},
	abstract = {We present a list of measures for a single trajectory, including measures that require the presence of other trajectories, such as the centrality of a trajectory amidst other trajectories. Then, we introduce three different views in order to extend measures of a single trajectory to a group, namely the representative view, the complete view and the area view. Furthermore, we give measures that exist only for a group of trajectories, like density and formation stability. We also show that it may be possible to define new measures by combining trajectory data with data from other sources, such as the environment where the entities move. Finally, we discuss several tasks: settlement selection, visualization and segmentation, where measures on groups of trajectories are necessary.},
	booktitle = {Societal Geo-innovation},
	editor = {Bregt, Arnold and Sarjakoski, Tapani and van Lammeren, Ron and Rip, Frans},
	year = {2017},
	pages = {311--330},
	publisher = {Springer International Publishing},
	address = {Cham},
	isbn = {978-3-319-56759-4}
}

@Article{Wismath:1992,
	author = {S.K. Wismath},
	title = {Computing the full visibility graph of a set of line segments},
	abstract = {Let S be a collection of n nonintersecting line segments in the plane in general position. Two segments u and v are defined as visible if a line segment could be drawn from some point of u to some point of v that intersects no other segment in S. The full visibility graph associated with S is denoted as G(S), and defined to be the graph whose n vertices correspond to the line segments of S and whose edge set represents the visibility relation between pairs of segments. A worst-case optimal O(n2) time and space algorithm for computing G(S) is presented.},
	keywords = {Computational geometry, visibility graph},
	journal = {Information Processing Letters},
	year = {1992},
	volume = {42},
	number = {5},
	pages = {257--261},
	issn = {0020-0190},
	doi = {https://doi.org/10.1016/0020-0190(92)90033-R},
	url = {https://www.sciencedirect.com/science/article/pii/002001909290033R},
}

@article{Xing:2022,
	author = {Xing, Jiankai and Luan, Fujun and Yan, Ling-Qi and Hu, Xuejun and Qian, Houde and Xu, Kun},
    title = {Differentiable Rendering using RGBXY Derivatives and Optimal Transport},
    journal = {ACM Trans. Graph.},
    issue_date = {December 2022},
    year = {2022},
    volume = {41},
    number = {6},
    numpages = {13},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    doi = {10.1145/3550454.3555479},
}

@InProceedings{XuLTJ:2022,
	author = {Xu, Yilun and Liu, Ziming and Tegmark, Max and Jaakkola, Tommi},
	title = {Poisson Flow Generative Models},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
	year = {2022},
	volume = {35},
 	pages = {16782--16795},
 	publisher = {Curran Associates, Inc.},
 	url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/6ad68a54eaa8f9bf6ac698b02ec05048-Paper-Conference.pdf}
}

@InProceedings{Yu:2022,
	author = {Zhongjie Yu and Devendra Singh Dhami and Kristian Kersting},
	title = {Sum-Product-Attention Networks: Leveraging Self-Attention in Energy-Based Probabilistic Circuits},
	booktitle = {The 5th Workshop on Tractable Probabilistic Modeling},
	year = {2022},
	url = {https://openreview.net/forum?id=Fs38z1uuCks}
}

@InProceedings{Yuan:2020,
	author = {Yuan, Bin and Yue, Xiaodong and Lv, Ying and Denoeux, Thierry},
	editor = {Li, Gang and Shen, Heng Tao and Yuan, Ye and Wang, Xiaoyang and Liu, Huawen and Zhao, Xiang},
	title = {Evidential Deep Neural Networks for Uncertain Data Classification},
	booktitle = {Knowledge Science, Engineering and Management},
	year = {2020},
	pages = {427--437},
	publisher = {Springer International Publishing},
	address = {Cham}
}

@Article{Zafar:2022,
	author = {Zafar, Afia and Aamir, Muhammad and Mohd Nawi, Nazri and Arshad, Ali and Riaz, Saman and Alruban, Abdulrahman and Dutta, Ashit Kumar and Almotairi, Sultan},
	title = {A Comparison of Pooling Methods for Convolutional Neural Networks},
	jouranl = {Applied Sciences},
	year = {2022},
	volume = {12},
	number = {17},
	doi = {10.3390/app12178643}
}

@InProceedings{Zaheer:2017,
	author = {Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Russ R and Smola, Alexander J},
	title = {Deep Sets},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	year = {2017},
 	volume = {30},
 	publisher = {Curran Associates, Inc.}
}

@InProceedings{Zhang:2017,
	author = {Yu Zhong Zhang},
  	title = {Online Learning Sum-Product Networks for Language Modeling},
	booktitle={Proceedings of the 2017 7th International Conference on Social Network, Communication and Education (SNCE 2017)},
	series = {Advances in Computer Science Research},
  	year = {2017},
  	volume = {82},
  	pages = {115--120},
  	publisher = {Atlantis Press},
  	doi = {https://doi.org/10.2991/snce-17.2017.24}
}

@Article{Zheng:2012,
	author = {Zheng, Xizhong and Rettinger, Robert},
	title = {Point-Separable Classes of Simple Computable Planar Curves},
  	journal = {Logical Methods in Computer Science (LMCS)},
  	year = {2012},
  	volume = {8},
  	number = {3},
  	doi = {10.2168/LMCS-8(3:15)2012}
}

@InProceedings{Zhou:2022,
	author = {Tian Zhou and Ziqing Ma and xue wang and Qingsong Wen and Liang Sun and Tao Yao and Wotao Yin and Rong Jin},
	title = {Fi{LM}: Frequency improved Legendre Memory Model for Long-term Time Series Forecasting},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
	year = {2022},
	url = {https://openreview.net/forum?id=zTQdHSQUQWc}
}

@Article{Zuo:2003,
	author = {Yijun Zuo},
	title = {Projection-Based Depth Functions and Associated Medians},
	abstract = {A class of projection-based depth functions is introduced and studied. These projection-based depth functions possess desirable properties of statistical depth functions and their sample versions possess strong and order ‚àön uniform consistency. Depth regions and contours induced from projection-based depth functions are investigated. Structural properties of depth regions and contours and general continuity and convergence results of sample depth regions are obtained. Affine equivariant multivariate medians induced from projection-based depth functions are probed. The limiting distributions as well as the strong and order ‚àön consistency of the sample projection medians are established. The finite sample performance of projection medians is compared with that of a leading depth-induced median, the Tukey halfspace median (induced from the Tukey halfspace depth function). It turns out that, with appropriate choices of univariate location and scale estimators, the projection medians have a very high finite sample breakdown point and relative efficiency, much higher than those of the halfspace median. Based on the results obtained, it is found that projection depth functions and projection medians behave very well overall compared with their competitors and consequently are good alternatives to statistical depth functions and affine equivariant multivariate location estimators, respectively.},
	journal = {The Annals of Statistics},
	volume = {31},
	number = {5},
 	pages = {1460--1490},
 	year = {2003},
 	publisher = {Institute of Mathematical Statistics},
 	ISSN = {00905364},
 	URL = {http://www.jstor.org/stable/3448384}
}

@Article{Zuo:2000,
	author = {Yijun Zuo and Robert Serfling},
	title = {General Notions of Statistical Depth Function},
 	abstract = {Statistical depth functions are being formulated ad hoc with increasing popularity in nonparametric inference for multivariate data. Here we introduce several general structures for depth functions, classify many existing examples as special cases, and establish results on the possession, or lack thereof, of four key properties desirable for depth functions in general. Roughly speaking, these properties may be described as: affine invariance, maximality at center, monotonicity relative to deepest point, and vanishing at infinity. This provides a more systematic basis for selection of a depth function. In particular, from these and other considerations it is found that the halfspace depth behaves very well overall in comparison with various competitors.}, 
 	journal = {The Annals of Statistics},
 	year = {2000},
 	volume = {28},
 	number = {2},
 	pages = {461--482},
 	publisher = {Institute of Mathematical Statistics},
 	ISSN = {00905364},
 	URL = {http://www.jstor.org/stable/2674037},
}
